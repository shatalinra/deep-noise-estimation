2021-05-10 11:32:04,648: <INFO> Trying model from Chuan et al
2021-05-10 11:32:06,067: <INFO> Training data size 14940
2021-05-10 11:32:06,069: <INFO> Training model: attempt 0
2021-05-10 11:32:06,210: <INFO> Model: "chuan_et_al"
2021-05-10 11:32:06,211: <INFO> _________________________________________________________________
2021-05-10 11:32:06,211: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-10 11:32:06,211: <INFO> =================================================================
2021-05-10 11:32:06,213: <INFO> conv-1 (Conv2D)              (None, 28, 28, 20)        1520      
2021-05-10 11:32:06,214: <INFO> _________________________________________________________________
2021-05-10 11:32:06,215: <INFO> max-pool-1 (MaxPooling2D)    (None, 14, 14, 20)        0         
2021-05-10 11:32:06,215: <INFO> _________________________________________________________________
2021-05-10 11:32:06,216: <INFO> conv-2 (Conv2D)              (None, 10, 10, 50)        25050     
2021-05-10 11:32:06,216: <INFO> _________________________________________________________________
2021-05-10 11:32:06,217: <INFO> max-pool-2 (MaxPooling2D)    (None, 5, 5, 50)          0         
2021-05-10 11:32:06,217: <INFO> _________________________________________________________________
2021-05-10 11:32:06,218: <INFO> conv-3 (Conv2D)              (None, 2, 2, 500)         400500    
2021-05-10 11:32:06,219: <INFO> _________________________________________________________________
2021-05-10 11:32:06,220: <INFO> conv-3-relu (ReLU)           (None, 2, 2, 500)         0         
2021-05-10 11:32:06,220: <INFO> _________________________________________________________________
2021-05-10 11:32:06,221: <INFO> conv-4 (Conv2D)              (None, 1, 1, 10)          20010     
2021-05-10 11:32:06,222: <INFO> _________________________________________________________________
2021-05-10 11:32:06,222: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-10 11:32:06,223: <INFO> =================================================================
2021-05-10 11:32:06,226: <INFO> Total params: 447,080
2021-05-10 11:32:06,226: <INFO> Trainable params: 447,080
2021-05-10 11:32:06,227: <INFO> Non-trainable params: 0
2021-05-10 11:32:06,228: <INFO> _________________________________________________________________
2021-05-10 11:32:11,263: <INFO> Epoch 0, loss 1.453287, change 1.453287, grad norm 13.475845, lr 0.000200
2021-05-10 11:32:13,896: <INFO> Epoch 5, loss 0.573422, change 0.879865, grad norm 50.275837, lr 0.000200
2021-05-10 11:32:16,739: <INFO> Epoch 10, loss 0.333653, change 0.239769, grad norm 126.225967, lr 0.000200
2021-05-10 11:32:20,005: <INFO> Epoch 15, loss 0.295518, change 0.038135, grad norm 245.050568, lr 0.000200
2021-05-10 11:32:22,960: <INFO> Epoch 20, loss 0.264654, change 0.030864, grad norm 126.708054, lr 0.000200
2021-05-10 11:32:25,896: <INFO> Epoch 25, loss 0.282182, change -0.017528, grad norm 257.297272, lr 0.000200
2021-05-10 11:32:28,796: <INFO> Epoch 30, loss 0.156424, change 0.125758, grad norm 103.682465, lr 0.000200
2021-05-10 11:32:31,649: <INFO> Epoch 35, loss 0.125789, change 0.030635, grad norm 35.137184, lr 0.000200
2021-05-10 11:32:34,537: <INFO> Epoch 40, loss 0.198284, change -0.072495, grad norm 290.372070, lr 0.000200
2021-05-10 11:32:37,404: <INFO> Epoch 45, loss 0.095822, change 0.102462, grad norm 37.756100, lr 0.000200
2021-05-10 11:32:40,284: <INFO> Epoch 50, loss 0.133047, change -0.037225, grad norm 168.899551, lr 0.000200
2021-05-10 11:32:43,166: <INFO> Epoch 55, loss 0.078721, change 0.054326, grad norm 47.672497, lr 0.000200
2021-05-10 11:32:45,977: <INFO> Epoch 60, loss 0.072369, change 0.006352, grad norm 81.206284, lr 0.000200
2021-05-10 11:32:48,849: <INFO> Epoch 65, loss 0.083448, change -0.011079, grad norm 71.157410, lr 0.000200
2021-05-10 11:32:51,704: <INFO> Epoch 70, loss 0.078786, change 0.004662, grad norm 69.166595, lr 0.000200
2021-05-10 11:32:54,571: <INFO> Epoch 75, loss 0.048519, change 0.030267, grad norm 10.333868, lr 0.000200
2021-05-10 11:32:57,466: <INFO> Epoch 80, loss 0.061577, change -0.013058, grad norm 86.877914, lr 0.000200
2021-05-10 11:33:00,352: <INFO> Epoch 85, loss 0.047963, change 0.013614, grad norm 38.105030, lr 0.000200
2021-05-10 11:33:03,186: <INFO> Epoch 90, loss 0.113397, change -0.065434, grad norm 328.398193, lr 0.000200
2021-05-10 11:33:06,061: <INFO> Epoch 95, loss 0.032052, change 0.081345, grad norm 17.602255, lr 0.000200
2021-05-10 11:33:08,363: <INFO> Training model: attempt 1
2021-05-10 11:33:08,462: <INFO> Model: "chuan_et_al"
2021-05-10 11:33:08,463: <INFO> _________________________________________________________________
2021-05-10 11:33:08,463: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-10 11:33:08,464: <INFO> =================================================================
2021-05-10 11:33:08,465: <INFO> conv-1 (Conv2D)              (None, 28, 28, 20)        1520      
2021-05-10 11:33:08,466: <INFO> _________________________________________________________________
2021-05-10 11:33:08,467: <INFO> max-pool-1 (MaxPooling2D)    (None, 14, 14, 20)        0         
2021-05-10 11:33:08,467: <INFO> _________________________________________________________________
2021-05-10 11:33:08,468: <INFO> conv-2 (Conv2D)              (None, 10, 10, 50)        25050     
2021-05-10 11:33:08,469: <INFO> _________________________________________________________________
2021-05-10 11:33:08,470: <INFO> max-pool-2 (MaxPooling2D)    (None, 5, 5, 50)          0         
2021-05-10 11:33:08,471: <INFO> _________________________________________________________________
2021-05-10 11:33:08,471: <INFO> conv-3 (Conv2D)              (None, 2, 2, 500)         400500    
2021-05-10 11:33:08,472: <INFO> _________________________________________________________________
2021-05-10 11:33:08,473: <INFO> conv-3-relu (ReLU)           (None, 2, 2, 500)         0         
2021-05-10 11:33:08,473: <INFO> _________________________________________________________________
2021-05-10 11:33:08,475: <INFO> conv-4 (Conv2D)              (None, 1, 1, 10)          20010     
2021-05-10 11:33:08,475: <INFO> _________________________________________________________________
2021-05-10 11:33:08,476: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-10 11:33:08,477: <INFO> =================================================================
2021-05-10 11:33:08,479: <INFO> Total params: 447,080
2021-05-10 11:33:08,479: <INFO> Trainable params: 447,080
2021-05-10 11:33:08,480: <INFO> Non-trainable params: 0
2021-05-10 11:33:08,480: <INFO> _________________________________________________________________
2021-05-10 11:33:09,815: <INFO> Epoch 0, loss 1.537874, change 1.537874, grad norm 4.187873, lr 0.000200
2021-05-10 11:33:12,699: <INFO> Epoch 5, loss 0.699707, change 0.838167, grad norm 53.481667, lr 0.000200
2021-05-10 11:33:15,518: <INFO> Epoch 10, loss 0.405424, change 0.294283, grad norm 33.699829, lr 0.000200
2021-05-10 11:33:18,402: <INFO> Epoch 15, loss 0.427895, change -0.022471, grad norm 193.094727, lr 0.000200
2021-05-10 11:33:21,247: <INFO> Epoch 20, loss 0.225185, change 0.202710, grad norm 30.302065, lr 0.000200
2021-05-10 11:33:24,118: <INFO> Epoch 25, loss 0.196454, change 0.028731, grad norm 88.020058, lr 0.000200
2021-05-10 11:33:27,000: <INFO> Epoch 30, loss 0.302527, change -0.106073, grad norm 253.161804, lr 0.000200
2021-05-10 11:33:29,871: <INFO> Epoch 35, loss 0.143913, change 0.158614, grad norm 29.257462, lr 0.000200
2021-05-10 11:33:32,758: <INFO> Epoch 40, loss 0.116965, change 0.026947, grad norm 68.118721, lr 0.000200
2021-05-10 11:33:35,602: <INFO> Epoch 45, loss 0.097082, change 0.019883, grad norm 39.957600, lr 0.000200
2021-05-10 11:33:38,498: <INFO> Epoch 50, loss 0.108700, change -0.011618, grad norm 62.693829, lr 0.000200
2021-05-10 11:33:41,379: <INFO> Epoch 55, loss 0.083565, change 0.025135, grad norm 19.844355, lr 0.000200
2021-05-10 11:33:44,280: <INFO> Epoch 60, loss 0.820299, change -0.736734, grad norm 1091.730835, lr 0.000200
2021-05-10 11:33:47,166: <INFO> Epoch 65, loss 0.070330, change 0.749969, grad norm 54.983776, lr 0.000200
2021-05-10 11:33:50,049: <INFO> Epoch 70, loss 0.057136, change 0.013194, grad norm 22.168165, lr 0.000200
2021-05-10 11:33:52,928: <INFO> Epoch 75, loss 0.073609, change -0.016473, grad norm 84.092224, lr 0.000200
2021-05-10 11:33:55,813: <INFO> Epoch 80, loss 0.058692, change 0.014917, grad norm 24.113775, lr 0.000200
2021-05-10 11:33:58,719: <INFO> Epoch 85, loss 0.046433, change 0.012258, grad norm 17.805470, lr 0.000200
2021-05-10 11:34:01,557: <INFO> Epoch 90, loss 0.066329, change -0.019895, grad norm 94.822380, lr 0.000200
2021-05-10 11:34:04,407: <INFO> Epoch 95, loss 0.049325, change 0.017004, grad norm 31.860025, lr 0.000200
2021-05-10 11:34:06,701: <INFO> Training model: attempt 2
2021-05-10 11:34:06,802: <INFO> Model: "chuan_et_al"
2021-05-10 11:34:06,803: <INFO> _________________________________________________________________
2021-05-10 11:34:06,803: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-10 11:34:06,804: <INFO> =================================================================
2021-05-10 11:34:06,805: <INFO> conv-1 (Conv2D)              (None, 28, 28, 20)        1520      
2021-05-10 11:34:06,805: <INFO> _________________________________________________________________
2021-05-10 11:34:06,807: <INFO> max-pool-1 (MaxPooling2D)    (None, 14, 14, 20)        0         
2021-05-10 11:34:06,807: <INFO> _________________________________________________________________
2021-05-10 11:34:06,808: <INFO> conv-2 (Conv2D)              (None, 10, 10, 50)        25050     
2021-05-10 11:34:06,809: <INFO> _________________________________________________________________
2021-05-10 11:34:06,810: <INFO> max-pool-2 (MaxPooling2D)    (None, 5, 5, 50)          0         
2021-05-10 11:34:06,810: <INFO> _________________________________________________________________
2021-05-10 11:34:06,812: <INFO> conv-3 (Conv2D)              (None, 2, 2, 500)         400500    
2021-05-10 11:34:06,812: <INFO> _________________________________________________________________
2021-05-10 11:34:06,813: <INFO> conv-3-relu (ReLU)           (None, 2, 2, 500)         0         
2021-05-10 11:34:06,814: <INFO> _________________________________________________________________
2021-05-10 11:34:06,815: <INFO> conv-4 (Conv2D)              (None, 1, 1, 10)          20010     
2021-05-10 11:34:06,816: <INFO> _________________________________________________________________
2021-05-10 11:34:06,817: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-10 11:34:06,817: <INFO> =================================================================
2021-05-10 11:34:06,820: <INFO> Total params: 447,080
2021-05-10 11:34:06,820: <INFO> Trainable params: 447,080
2021-05-10 11:34:06,821: <INFO> Non-trainable params: 0
2021-05-10 11:34:06,821: <INFO> _________________________________________________________________
2021-05-10 11:34:08,155: <INFO> Epoch 0, loss 1.442456, change 1.442456, grad norm 6.014821, lr 0.000200
2021-05-10 11:34:11,031: <INFO> Epoch 5, loss 0.595727, change 0.846729, grad norm 20.523525, lr 0.000200
2021-05-10 11:34:13,953: <INFO> Epoch 10, loss 0.633529, change -0.037802, grad norm 283.241608, lr 0.000200
2021-05-10 11:34:16,699: <INFO> Epoch 15, loss 0.251551, change 0.381978, grad norm 23.361858, lr 0.000200
2021-05-10 11:34:19,518: <INFO> Epoch 20, loss 0.216926, change 0.034626, grad norm 113.178741, lr 0.000200
2021-05-10 11:34:22,346: <INFO> Epoch 25, loss 2.468592, change -2.251667, grad norm 1542.257324, lr 0.000200
2021-05-10 11:34:25,168: <INFO> Epoch 30, loss 0.134094, change 2.334498, grad norm 11.967726, lr 0.000200
2021-05-10 11:34:27,962: <INFO> Epoch 35, loss 0.394845, change -0.260751, grad norm 457.658020, lr 0.000200
2021-05-10 11:34:30,783: <INFO> Epoch 40, loss 0.116008, change 0.278837, grad norm 94.787918, lr 0.000200
2021-05-10 11:34:33,578: <INFO> Epoch 45, loss 0.103278, change 0.012730, grad norm 29.297131, lr 0.000200
2021-05-10 11:34:36,422: <INFO> Epoch 50, loss 0.090851, change 0.012427, grad norm 15.965890, lr 0.000200
2021-05-10 11:34:39,248: <INFO> Epoch 55, loss 0.075042, change 0.015809, grad norm 22.298838, lr 0.000200
2021-05-10 11:34:42,068: <INFO> Epoch 60, loss 0.061923, change 0.013119, grad norm 11.922110, lr 0.000200
2021-05-10 11:34:44,883: <INFO> Epoch 65, loss 0.083352, change -0.021429, grad norm 90.159889, lr 0.000200
2021-05-10 11:34:47,689: <INFO> Epoch 70, loss 0.055475, change 0.027877, grad norm 46.768852, lr 0.000200
2021-05-10 11:34:50,514: <INFO> Epoch 75, loss 0.084975, change -0.029500, grad norm 134.678619, lr 0.000200
2021-05-10 11:34:53,348: <INFO> Epoch 80, loss 0.047767, change 0.037208, grad norm 27.829399, lr 0.000200
2021-05-10 11:34:56,141: <INFO> Epoch 85, loss 0.043832, change 0.003935, grad norm 33.426201, lr 0.000200
2021-05-10 11:34:58,943: <INFO> Epoch 90, loss 1.031343, change -0.987511, grad norm 931.447205, lr 0.000200
2021-05-10 11:35:01,788: <INFO> Epoch 95, loss 0.094684, change 0.936659, grad norm 198.479675, lr 0.000200
2021-05-10 11:35:04,678: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-05-10 11:35:04,699: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-05-10 11:35:06,452: <INFO> Assets written to: chuah_et_al\assets
2021-05-10 11:35:06,508: <INFO> Best loss is 0.031904
