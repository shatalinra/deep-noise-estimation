2021-05-10 11:56:07,973: <INFO> Trying model from Chuan et al
2021-05-10 11:56:09,188: <INFO> Training data size 14940
2021-05-10 11:56:09,189: <INFO> Training model: attempt 0
2021-05-10 11:56:09,326: <INFO> Model: "chuan_et_al"
2021-05-10 11:56:09,327: <INFO> _________________________________________________________________
2021-05-10 11:56:09,328: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-10 11:56:09,328: <INFO> =================================================================
2021-05-10 11:56:09,330: <INFO> conv-1 (Conv2D)              (None, 28, 28, 20)        1520      
2021-05-10 11:56:09,330: <INFO> _________________________________________________________________
2021-05-10 11:56:09,331: <INFO> max-pool-1 (MaxPooling2D)    (None, 14, 14, 20)        0         
2021-05-10 11:56:09,331: <INFO> _________________________________________________________________
2021-05-10 11:56:09,333: <INFO> conv-2 (Conv2D)              (None, 10, 10, 50)        25050     
2021-05-10 11:56:09,333: <INFO> _________________________________________________________________
2021-05-10 11:56:09,334: <INFO> max-pool-2 (MaxPooling2D)    (None, 5, 5, 50)          0         
2021-05-10 11:56:09,334: <INFO> _________________________________________________________________
2021-05-10 11:56:09,335: <INFO> conv-3 (Conv2D)              (None, 2, 2, 500)         400500    
2021-05-10 11:56:09,336: <INFO> _________________________________________________________________
2021-05-10 11:56:09,337: <INFO> conv-3-relu (ReLU)           (None, 2, 2, 500)         0         
2021-05-10 11:56:09,337: <INFO> _________________________________________________________________
2021-05-10 11:56:09,338: <INFO> conv-4 (Conv2D)              (None, 1, 1, 10)          20010     
2021-05-10 11:56:09,339: <INFO> _________________________________________________________________
2021-05-10 11:56:09,340: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-10 11:56:09,340: <INFO> =================================================================
2021-05-10 11:56:09,343: <INFO> Total params: 447,080
2021-05-10 11:56:09,344: <INFO> Trainable params: 447,080
2021-05-10 11:56:09,344: <INFO> Non-trainable params: 0
2021-05-10 11:56:09,345: <INFO> _________________________________________________________________
2021-05-10 11:56:14,265: <INFO> Epoch 0, loss 1.974139, change 1.974139, grad norm 2.150077, lr 0.000100
2021-05-10 11:56:16,107: <INFO> Epoch 5, loss 1.152759, change 0.821380, grad norm 17.743832, lr 0.000100
2021-05-10 11:56:18,176: <INFO> Epoch 10, loss 0.938340, change 0.214419, grad norm 18.622042, lr 0.000100
2021-05-10 11:56:20,242: <INFO> Epoch 15, loss 0.810496, change 0.127844, grad norm 41.338345, lr 0.000100
2021-05-10 11:56:22,313: <INFO> Epoch 20, loss 0.666249, change 0.144247, grad norm 28.458347, lr 0.000100
2021-05-10 11:56:24,373: <INFO> Epoch 25, loss 0.569936, change 0.096313, grad norm 74.513855, lr 0.000100
2021-05-10 11:56:26,436: <INFO> Epoch 30, loss 0.514066, change 0.055870, grad norm 104.733444, lr 0.000100
2021-05-10 11:56:28,496: <INFO> Epoch 35, loss 0.412905, change 0.101160, grad norm 15.849080, lr 0.000100
2021-05-10 11:56:30,546: <INFO> Epoch 40, loss 0.368218, change 0.044687, grad norm 7.265375, lr 0.000100
2021-05-10 11:56:32,616: <INFO> Epoch 45, loss 0.370657, change -0.002439, grad norm 70.514160, lr 0.000100
2021-05-10 11:56:34,675: <INFO> Epoch 50, loss 0.317470, change 0.053187, grad norm 14.297665, lr 0.000100
2021-05-10 11:56:36,741: <INFO> Epoch 55, loss 0.306286, change 0.011184, grad norm 29.030336, lr 0.000100
2021-05-10 11:56:38,815: <INFO> Epoch 60, loss 0.267052, change 0.039234, grad norm 16.221741, lr 0.000100
2021-05-10 11:56:40,879: <INFO> Epoch 65, loss 0.262536, change 0.004516, grad norm 63.947281, lr 0.000100
2021-05-10 11:56:42,941: <INFO> Epoch 70, loss 0.243107, change 0.019429, grad norm 80.561104, lr 0.000100
2021-05-10 11:56:45,004: <INFO> Epoch 75, loss 0.253137, change -0.010031, grad norm 88.218010, lr 0.000100
2021-05-10 11:56:47,074: <INFO> Epoch 80, loss 0.213799, change 0.039338, grad norm 76.588806, lr 0.000100
2021-05-10 11:56:49,152: <INFO> Epoch 85, loss 0.201501, change 0.012298, grad norm 45.866959, lr 0.000100
2021-05-10 11:56:51,214: <INFO> Epoch 90, loss 0.210183, change -0.008682, grad norm 128.683456, lr 0.000100
2021-05-10 11:56:53,279: <INFO> Epoch 95, loss 0.197804, change 0.012379, grad norm 114.049232, lr 0.000100
2021-05-10 11:56:55,341: <INFO> Epoch 100, loss 0.170126, change 0.027678, grad norm 76.555328, lr 0.000100
2021-05-10 11:56:57,406: <INFO> Epoch 105, loss 0.189543, change -0.019418, grad norm 149.356216, lr 0.000100
2021-05-10 11:56:59,492: <INFO> Epoch 110, loss 0.150833, change 0.038710, grad norm 15.738543, lr 0.000100
2021-05-10 11:57:01,557: <INFO> Epoch 115, loss 0.142621, change 0.008212, grad norm 10.869049, lr 0.000100
2021-05-10 11:57:03,631: <INFO> Epoch 120, loss 0.151228, change -0.008607, grad norm 118.554291, lr 0.000100
2021-05-10 11:57:05,697: <INFO> Epoch 125, loss 0.131883, change 0.019345, grad norm 21.696877, lr 0.000100
2021-05-10 11:57:07,763: <INFO> Epoch 130, loss 0.166423, change -0.034540, grad norm 208.192352, lr 0.000100
2021-05-10 11:57:09,824: <INFO> Epoch 135, loss 0.122761, change 0.043662, grad norm 75.603371, lr 0.000100
2021-05-10 11:57:11,901: <INFO> Epoch 140, loss 0.115896, change 0.006865, grad norm 71.385719, lr 0.000100
2021-05-10 11:57:13,976: <INFO> Epoch 145, loss 0.115934, change -0.000038, grad norm 71.827003, lr 0.000100
2021-05-10 11:57:16,033: <INFO> Epoch 150, loss 0.122037, change -0.006103, grad norm 92.403702, lr 0.000100
2021-05-10 11:57:18,099: <INFO> Epoch 155, loss 0.112747, change 0.009289, grad norm 82.906898, lr 0.000100
2021-05-10 11:57:20,160: <INFO> Epoch 160, loss 0.096815, change 0.015932, grad norm 46.103989, lr 0.000100
2021-05-10 11:57:22,232: <INFO> Epoch 165, loss 0.091012, change 0.005803, grad norm 12.575255, lr 0.000100
2021-05-10 11:57:24,309: <INFO> Epoch 170, loss 0.086068, change 0.004944, grad norm 35.437462, lr 0.000100
2021-05-10 11:57:26,373: <INFO> Epoch 175, loss 0.096948, change -0.010879, grad norm 87.983467, lr 0.000100
2021-05-10 11:57:28,442: <INFO> Epoch 180, loss 0.078766, change 0.018181, grad norm 7.888090, lr 0.000100
2021-05-10 11:57:30,506: <INFO> Epoch 185, loss 0.131871, change -0.053105, grad norm 202.022018, lr 0.000100
2021-05-10 11:57:32,569: <INFO> Epoch 190, loss 0.114739, change 0.017132, grad norm 54.498123, lr 0.000100
2021-05-10 11:57:34,634: <INFO> Epoch 195, loss 0.073994, change 0.040745, grad norm 10.817708, lr 0.000100
2021-05-10 11:57:36,710: <INFO> Epoch 200, loss 0.072172, change 0.001822, grad norm 4.752819, lr 0.000100
2021-05-10 11:57:38,773: <INFO> Epoch 205, loss 0.073345, change -0.001173, grad norm 50.133198, lr 0.000100
2021-05-10 11:57:40,850: <INFO> Epoch 210, loss 0.092691, change -0.019346, grad norm 122.447197, lr 0.000100
2021-05-10 11:57:42,929: <INFO> Epoch 215, loss 0.066154, change 0.026537, grad norm 2.707163, lr 0.000100
2021-05-10 11:57:45,016: <INFO> Epoch 220, loss 0.066832, change -0.000679, grad norm 14.378867, lr 0.000100
2021-05-10 11:57:47,080: <INFO> Epoch 225, loss 0.062406, change 0.004426, grad norm 7.727763, lr 0.000100
2021-05-10 11:57:49,156: <INFO> Epoch 230, loss 0.062736, change -0.000330, grad norm 41.704056, lr 0.000100
2021-05-10 11:57:51,224: <INFO> Epoch 235, loss 0.094681, change -0.031945, grad norm 169.538834, lr 0.000100
2021-05-10 11:57:53,291: <INFO> Epoch 240, loss 0.064260, change 0.030421, grad norm 50.035664, lr 0.000100
2021-05-10 11:57:55,372: <INFO> Epoch 245, loss 0.055639, change 0.008621, grad norm 37.400860, lr 0.000100
2021-05-10 11:57:57,448: <INFO> Epoch 250, loss 0.054317, change 0.001322, grad norm 5.130220, lr 0.000100
2021-05-10 11:57:59,518: <INFO> Epoch 255, loss 0.051964, change 0.002353, grad norm 10.445069, lr 0.000100
2021-05-10 11:58:01,600: <INFO> Epoch 260, loss 0.056359, change -0.004395, grad norm 65.901306, lr 0.000100
2021-05-10 11:58:03,673: <INFO> Epoch 265, loss 0.050541, change 0.005818, grad norm 19.330015, lr 0.000100
2021-05-10 11:58:05,740: <INFO> Epoch 270, loss 0.050728, change -0.000187, grad norm 38.236698, lr 0.000100
2021-05-10 11:58:07,816: <INFO> Epoch 275, loss 0.048789, change 0.001940, grad norm 23.348942, lr 0.000100
2021-05-10 11:58:09,885: <INFO> Epoch 280, loss 0.042765, change 0.006024, grad norm 16.517214, lr 0.000100
2021-05-10 11:58:11,970: <INFO> Epoch 285, loss 0.060448, change -0.017683, grad norm 99.986397, lr 0.000100
2021-05-10 11:58:14,042: <INFO> Epoch 290, loss 0.048892, change 0.011556, grad norm 33.610043, lr 0.000100
2021-05-10 11:58:16,118: <INFO> Epoch 295, loss 0.042140, change 0.006752, grad norm 36.531841, lr 0.000100
2021-05-10 11:58:18,185: <INFO> Epoch 300, loss 0.040562, change 0.001579, grad norm 28.193598, lr 0.000100
2021-05-10 11:58:20,249: <INFO> Epoch 305, loss 0.043863, change -0.003302, grad norm 50.637932, lr 0.000100
2021-05-10 11:58:22,329: <INFO> Epoch 310, loss 0.035689, change 0.008174, grad norm 5.770772, lr 0.000100
2021-05-10 11:58:24,393: <INFO> Epoch 315, loss 0.044930, change -0.009241, grad norm 71.314110, lr 0.000100
2021-05-10 11:58:26,465: <INFO> Epoch 320, loss 0.038570, change 0.006360, grad norm 50.412514, lr 0.000100
2021-05-10 11:58:28,529: <INFO> Epoch 325, loss 0.050326, change -0.011756, grad norm 104.931862, lr 0.000100
2021-05-10 11:58:30,603: <INFO> Epoch 330, loss 0.038659, change 0.011667, grad norm 15.348792, lr 0.000100
2021-05-10 11:58:32,684: <INFO> Epoch 335, loss 0.031790, change 0.006869, grad norm 3.917223, lr 0.000100
2021-05-10 11:58:34,750: <INFO> Epoch 340, loss 0.037790, change -0.006000, grad norm 23.683418, lr 0.000100
2021-05-10 11:58:36,833: <INFO> Epoch 345, loss 0.052335, change -0.014545, grad norm 113.846107, lr 0.000100
2021-05-10 11:58:38,899: <INFO> Epoch 350, loss 0.029112, change 0.023222, grad norm 8.562307, lr 0.000100
2021-05-10 11:58:40,972: <INFO> Epoch 355, loss 0.026955, change 0.002157, grad norm 3.627838, lr 0.000100
2021-05-10 11:58:43,031: <INFO> Epoch 360, loss 0.034437, change -0.007482, grad norm 9.718079, lr 0.000100
2021-05-10 11:58:45,091: <INFO> Epoch 365, loss 0.029732, change 0.004705, grad norm 15.657032, lr 0.000100
2021-05-10 11:58:47,156: <INFO> Epoch 370, loss 0.070775, change -0.041042, grad norm 169.326019, lr 0.000100
2021-05-10 11:58:49,246: <INFO> Epoch 375, loss 0.028516, change 0.042258, grad norm 35.515205, lr 0.000100
2021-05-10 11:58:51,317: <INFO> Epoch 380, loss 0.024395, change 0.004121, grad norm 7.337547, lr 0.000100
2021-05-10 11:58:53,384: <INFO> Epoch 385, loss 0.023536, change 0.000859, grad norm 3.625867, lr 0.000100
2021-05-10 11:58:55,449: <INFO> Epoch 390, loss 0.024563, change -0.001026, grad norm 20.242992, lr 0.000100
2021-05-10 11:58:57,515: <INFO> Epoch 395, loss 0.034570, change -0.010007, grad norm 71.260406, lr 0.000100
2021-05-10 11:58:59,581: <INFO> Epoch 400, loss 0.021906, change 0.012664, grad norm 1.911774, lr 0.000100
2021-05-10 11:59:01,668: <INFO> Epoch 405, loss 0.020721, change 0.001185, grad norm 8.178689, lr 0.000100
2021-05-10 11:59:04,178: <INFO> Epoch 410, loss 0.021902, change -0.001181, grad norm 25.480671, lr 0.000100
2021-05-10 11:59:06,976: <INFO> Epoch 415, loss 0.019394, change 0.002507, grad norm 4.383203, lr 0.000100
2021-05-10 11:59:09,297: <INFO> Epoch 420, loss 0.019278, change 0.000116, grad norm 18.072140, lr 0.000100
2021-05-10 11:59:11,413: <INFO> Epoch 425, loss 0.019572, change -0.000294, grad norm 8.387704, lr 0.000100
2021-05-10 11:59:13,871: <INFO> Epoch 430, loss 0.089561, change -0.069988, grad norm 304.528992, lr 0.000100
2021-05-10 11:59:15,954: <INFO> Epoch 435, loss 0.023904, change 0.065657, grad norm 44.902737, lr 0.000100
2021-05-10 11:59:18,030: <INFO> Epoch 440, loss 0.021788, change 0.002117, grad norm 45.516560, lr 0.000100
2021-05-10 11:59:20,103: <INFO> Epoch 445, loss 0.020202, change 0.001586, grad norm 4.049708, lr 0.000100
2021-05-10 11:59:22,174: <INFO> Epoch 450, loss 0.017855, change 0.002347, grad norm 6.455188, lr 0.000100
2021-05-10 11:59:24,250: <INFO> Epoch 455, loss 0.016774, change 0.001081, grad norm 2.684441, lr 0.000100
2021-05-10 11:59:26,326: <INFO> Epoch 460, loss 0.017296, change -0.000521, grad norm 18.281000, lr 0.000100
2021-05-10 11:59:28,397: <INFO> Epoch 465, loss 0.017729, change -0.000433, grad norm 28.509472, lr 0.000100
2021-05-10 11:59:30,460: <INFO> Epoch 470, loss 0.015044, change 0.002685, grad norm 2.876776, lr 0.000100
2021-05-10 11:59:32,540: <INFO> Epoch 475, loss 0.014346, change 0.000698, grad norm 8.759567, lr 0.000100
2021-05-10 11:59:34,608: <INFO> Epoch 480, loss 0.020499, change -0.006153, grad norm 51.725109, lr 0.000100
2021-05-10 11:59:36,676: <INFO> Epoch 485, loss 0.013776, change 0.006723, grad norm 3.630720, lr 0.000100
2021-05-10 11:59:38,742: <INFO> Epoch 490, loss 0.030755, change -0.016979, grad norm 52.332409, lr 0.000100
2021-05-10 11:59:40,808: <INFO> Epoch 495, loss 0.014760, change 0.015995, grad norm 7.867579, lr 0.000100
2021-05-10 11:59:42,469: <INFO> Training model: attempt 1
2021-05-10 11:59:42,569: <INFO> Model: "chuan_et_al"
2021-05-10 11:59:42,569: <INFO> _________________________________________________________________
2021-05-10 11:59:42,570: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-10 11:59:42,570: <INFO> =================================================================
2021-05-10 11:59:42,572: <INFO> conv-1 (Conv2D)              (None, 28, 28, 20)        1520      
2021-05-10 11:59:42,572: <INFO> _________________________________________________________________
2021-05-10 11:59:42,574: <INFO> max-pool-1 (MaxPooling2D)    (None, 14, 14, 20)        0         
2021-05-10 11:59:42,575: <INFO> _________________________________________________________________
2021-05-10 11:59:42,576: <INFO> conv-2 (Conv2D)              (None, 10, 10, 50)        25050     
2021-05-10 11:59:42,576: <INFO> _________________________________________________________________
2021-05-10 11:59:42,577: <INFO> max-pool-2 (MaxPooling2D)    (None, 5, 5, 50)          0         
2021-05-10 11:59:42,578: <INFO> _________________________________________________________________
2021-05-10 11:59:42,579: <INFO> conv-3 (Conv2D)              (None, 2, 2, 500)         400500    
2021-05-10 11:59:42,579: <INFO> _________________________________________________________________
2021-05-10 11:59:42,580: <INFO> conv-3-relu (ReLU)           (None, 2, 2, 500)         0         
2021-05-10 11:59:42,581: <INFO> _________________________________________________________________
2021-05-10 11:59:42,582: <INFO> conv-4 (Conv2D)              (None, 1, 1, 10)          20010     
2021-05-10 11:59:42,582: <INFO> _________________________________________________________________
2021-05-10 11:59:42,583: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-10 11:59:42,584: <INFO> =================================================================
2021-05-10 11:59:42,586: <INFO> Total params: 447,080
2021-05-10 11:59:42,586: <INFO> Trainable params: 447,080
2021-05-10 11:59:42,586: <INFO> Non-trainable params: 0
2021-05-10 11:59:42,587: <INFO> _________________________________________________________________
2021-05-10 11:59:43,804: <INFO> Epoch 0, loss 1.904225, change 1.904225, grad norm 1.085691, lr 0.000100
2021-05-10 11:59:45,892: <INFO> Epoch 5, loss 1.147874, change 0.756351, grad norm 17.209867, lr 0.000100
2021-05-10 11:59:47,978: <INFO> Epoch 10, loss 0.936155, change 0.211720, grad norm 23.101460, lr 0.000100
2021-05-10 11:59:50,045: <INFO> Epoch 15, loss 0.816837, change 0.119317, grad norm 36.445389, lr 0.000100
2021-05-10 11:59:52,113: <INFO> Epoch 20, loss 0.713651, change 0.103187, grad norm 68.401909, lr 0.000100
2021-05-10 11:59:54,194: <INFO> Epoch 25, loss 0.577175, change 0.136476, grad norm 8.387027, lr 0.000100
2021-05-10 11:59:56,272: <INFO> Epoch 30, loss 0.497701, change 0.079474, grad norm 24.374153, lr 0.000100
2021-05-10 11:59:58,349: <INFO> Epoch 35, loss 0.437916, change 0.059785, grad norm 26.025412, lr 0.000100
2021-05-10 12:00:00,428: <INFO> Epoch 40, loss 0.412722, change 0.025195, grad norm 81.055481, lr 0.000100
2021-05-10 12:00:02,499: <INFO> Epoch 45, loss 0.342382, change 0.070339, grad norm 7.328571, lr 0.000100
2021-05-10 12:00:04,571: <INFO> Epoch 50, loss 0.319952, change 0.022430, grad norm 35.245567, lr 0.000100
2021-05-10 12:00:06,660: <INFO> Epoch 55, loss 0.290027, change 0.029925, grad norm 20.938278, lr 0.000100
2021-05-10 12:00:08,762: <INFO> Epoch 60, loss 0.276854, change 0.013173, grad norm 59.660370, lr 0.000100
2021-05-10 12:00:10,830: <INFO> Epoch 65, loss 0.245637, change 0.031216, grad norm 12.532205, lr 0.000100
2021-05-10 12:00:12,904: <INFO> Epoch 70, loss 0.229248, change 0.016390, grad norm 25.699760, lr 0.000100
2021-05-10 12:00:14,985: <INFO> Epoch 75, loss 0.225302, change 0.003946, grad norm 69.281898, lr 0.000100
2021-05-10 12:00:17,061: <INFO> Epoch 80, loss 0.197738, change 0.027564, grad norm 20.451244, lr 0.000100
2021-05-10 12:00:19,124: <INFO> Epoch 85, loss 0.215704, change -0.017965, grad norm 73.403709, lr 0.000100
2021-05-10 12:00:21,214: <INFO> Epoch 90, loss 0.185483, change 0.030220, grad norm 74.169083, lr 0.000100
2021-05-10 12:00:23,279: <INFO> Epoch 95, loss 0.175187, change 0.010297, grad norm 66.851021, lr 0.000100
2021-05-10 12:00:25,364: <INFO> Epoch 100, loss 0.153250, change 0.021937, grad norm 7.559888, lr 0.000100
2021-05-10 12:00:27,433: <INFO> Epoch 105, loss 0.150192, change 0.003058, grad norm 40.152561, lr 0.000100
2021-05-10 12:00:29,515: <INFO> Epoch 110, loss 0.142758, change 0.007434, grad norm 7.557801, lr 0.000100
2021-05-10 12:00:31,581: <INFO> Epoch 115, loss 0.144249, change -0.001492, grad norm 94.755165, lr 0.000100
2021-05-10 12:00:33,666: <INFO> Epoch 120, loss 0.150571, change -0.006322, grad norm 114.523743, lr 0.000100
2021-05-10 12:00:35,744: <INFO> Epoch 125, loss 0.238038, change -0.087467, grad norm 246.469162, lr 0.000100
2021-05-10 12:00:37,818: <INFO> Epoch 130, loss 0.113324, change 0.124714, grad norm 8.746561, lr 0.000100
2021-05-10 12:00:39,897: <INFO> Epoch 135, loss 0.123951, change -0.010627, grad norm 66.869713, lr 0.000100
2021-05-10 12:00:41,978: <INFO> Epoch 140, loss 0.104005, change 0.019946, grad norm 7.292602, lr 0.000100
2021-05-10 12:00:44,045: <INFO> Epoch 145, loss 0.099502, change 0.004503, grad norm 20.483490, lr 0.000100
2021-05-10 12:00:46,136: <INFO> Epoch 150, loss 0.097766, change 0.001736, grad norm 38.051819, lr 0.000100
2021-05-10 12:00:48,218: <INFO> Epoch 155, loss 0.096779, change 0.000987, grad norm 59.107037, lr 0.000100
2021-05-10 12:00:50,298: <INFO> Epoch 160, loss 0.086637, change 0.010142, grad norm 16.761934, lr 0.000100
2021-05-10 12:00:52,368: <INFO> Epoch 165, loss 0.130897, change -0.044260, grad norm 162.960236, lr 0.000100
2021-05-10 12:00:54,442: <INFO> Epoch 170, loss 0.233561, change -0.102664, grad norm 274.674194, lr 0.000100
2021-05-10 12:00:56,522: <INFO> Epoch 175, loss 0.090951, change 0.142609, grad norm 67.661545, lr 0.000100
2021-05-10 12:00:58,597: <INFO> Epoch 180, loss 0.083942, change 0.007010, grad norm 57.431553, lr 0.000100
2021-05-10 12:01:00,675: <INFO> Epoch 185, loss 0.083092, change 0.000849, grad norm 78.375664, lr 0.000100
2021-05-10 12:01:02,757: <INFO> Epoch 190, loss 0.070217, change 0.012875, grad norm 8.732288, lr 0.000100
2021-05-10 12:01:04,826: <INFO> Epoch 195, loss 0.069282, change 0.000935, grad norm 13.804686, lr 0.000100
2021-05-10 12:01:06,901: <INFO> Epoch 200, loss 0.065537, change 0.003745, grad norm 21.988771, lr 0.000100
2021-05-10 12:01:08,970: <INFO> Epoch 205, loss 0.069868, change -0.004331, grad norm 61.633713, lr 0.000100
2021-05-10 12:01:11,057: <INFO> Epoch 210, loss 0.349821, change -0.279954, grad norm 539.045776, lr 0.000100
2021-05-10 12:01:13,136: <INFO> Epoch 215, loss 0.070937, change 0.278884, grad norm 71.371872, lr 0.000100
2021-05-10 12:01:15,209: <INFO> Epoch 220, loss 0.060501, change 0.010436, grad norm 35.793743, lr 0.000100
2021-05-10 12:01:17,279: <INFO> Epoch 225, loss 0.078941, change -0.018439, grad norm 112.070930, lr 0.000100
2021-05-10 12:01:19,361: <INFO> Epoch 230, loss 0.083680, change -0.004740, grad norm 144.517624, lr 0.000100
2021-05-10 12:01:21,436: <INFO> Epoch 235, loss 0.179171, change -0.095490, grad norm 311.847656, lr 0.000100
2021-05-10 12:01:23,512: <INFO> Epoch 240, loss 0.050747, change 0.128423, grad norm 6.957589, lr 0.000100
2021-05-10 12:01:25,577: <INFO> Epoch 245, loss 0.051995, change -0.001248, grad norm 28.563078, lr 0.000100
2021-05-10 12:01:27,660: <INFO> Epoch 250, loss 0.058145, change -0.006150, grad norm 69.161095, lr 0.000100
2021-05-10 12:01:29,738: <INFO> Epoch 255, loss 0.066852, change -0.008707, grad norm 102.649551, lr 0.000100
2021-05-10 12:01:31,815: <INFO> Epoch 260, loss 0.059318, change 0.007533, grad norm 76.339211, lr 0.000100
2021-05-10 12:01:33,895: <INFO> Epoch 265, loss 0.061360, change -0.002041, grad norm 33.930656, lr 0.000100
2021-05-10 12:01:35,996: <INFO> Epoch 270, loss 0.045717, change 0.015643, grad norm 18.187649, lr 0.000100
2021-05-10 12:01:38,079: <INFO> Epoch 275, loss 0.049671, change -0.003953, grad norm 50.861069, lr 0.000100
2021-05-10 12:01:40,158: <INFO> Epoch 280, loss 0.043094, change 0.006577, grad norm 24.383665, lr 0.000100
2021-05-10 12:01:42,238: <INFO> Epoch 285, loss 0.044086, change -0.000992, grad norm 27.439106, lr 0.000100
2021-05-10 12:01:44,322: <INFO> Epoch 290, loss 0.042629, change 0.001457, grad norm 44.935902, lr 0.000100
2021-05-10 12:01:46,402: <INFO> Epoch 295, loss 0.038866, change 0.003763, grad norm 16.910751, lr 0.000100
2021-05-10 12:01:48,470: <INFO> Epoch 300, loss 0.047968, change -0.009102, grad norm 85.148056, lr 0.000100
2021-05-10 12:01:50,549: <INFO> Epoch 305, loss 0.037676, change 0.010292, grad norm 38.223587, lr 0.000100
2021-05-10 12:01:52,628: <INFO> Epoch 310, loss 0.037453, change 0.000223, grad norm 43.390469, lr 0.000100
2021-05-10 12:01:54,709: <INFO> Epoch 315, loss 0.032771, change 0.004682, grad norm 24.865988, lr 0.000100
2021-05-10 12:01:56,791: <INFO> Epoch 320, loss 0.061590, change -0.028819, grad norm 122.942543, lr 0.000100
2021-05-10 12:01:58,863: <INFO> Epoch 325, loss 0.056140, change 0.005450, grad norm 22.630560, lr 0.000100
2021-05-10 12:02:00,939: <INFO> Epoch 330, loss 0.037116, change 0.019024, grad norm 6.268724, lr 0.000100
2021-05-10 12:02:03,020: <INFO> Epoch 335, loss 0.035401, change 0.001714, grad norm 29.577749, lr 0.000100
2021-05-10 12:02:05,090: <INFO> Epoch 340, loss 0.031657, change 0.003744, grad norm 21.471481, lr 0.000100
2021-05-10 12:02:07,178: <INFO> Epoch 345, loss 0.029901, change 0.001756, grad norm 13.281951, lr 0.000100
2021-05-10 12:02:09,261: <INFO> Epoch 350, loss 0.028359, change 0.001542, grad norm 3.381798, lr 0.000100
2021-05-10 12:02:11,329: <INFO> Epoch 355, loss 0.038251, change -0.009892, grad norm 64.884239, lr 0.000100
2021-05-10 12:02:13,415: <INFO> Epoch 360, loss 0.026408, change 0.011843, grad norm 17.045122, lr 0.000100
2021-05-10 12:02:15,492: <INFO> Epoch 365, loss 0.049398, change -0.022990, grad norm 122.058983, lr 0.000100
2021-05-10 12:02:17,559: <INFO> Epoch 370, loss 0.030882, change 0.018516, grad norm 12.093736, lr 0.000100
2021-05-10 12:02:19,631: <INFO> Epoch 375, loss 0.027205, change 0.003677, grad norm 7.555227, lr 0.000100
2021-05-10 12:02:21,697: <INFO> Epoch 380, loss 0.024100, change 0.003105, grad norm 10.437140, lr 0.000100
2021-05-10 12:02:23,782: <INFO> Epoch 385, loss 0.024706, change -0.000606, grad norm 17.309698, lr 0.000100
2021-05-10 12:02:25,868: <INFO> Epoch 390, loss 0.026522, change -0.001816, grad norm 40.615871, lr 0.000100
2021-05-10 12:02:27,936: <INFO> Epoch 395, loss 0.036287, change -0.009765, grad norm 83.699745, lr 0.000100
2021-05-10 12:02:30,010: <INFO> Epoch 400, loss 0.021750, change 0.014537, grad norm 25.693123, lr 0.000100
2021-05-10 12:02:32,085: <INFO> Epoch 405, loss 0.019208, change 0.002542, grad norm 11.677636, lr 0.000100
2021-05-10 12:02:34,164: <INFO> Epoch 410, loss 0.019358, change -0.000150, grad norm 1.201473, lr 0.000100
2021-05-10 12:02:36,248: <INFO> Epoch 415, loss 0.019053, change 0.000305, grad norm 6.830653, lr 0.000100
2021-05-10 12:02:38,319: <INFO> Epoch 420, loss 0.037981, change -0.018929, grad norm 93.616798, lr 0.000100
2021-05-10 12:02:40,389: <INFO> Epoch 425, loss 0.023549, change 0.014433, grad norm 14.964532, lr 0.000100
2021-05-10 12:02:42,465: <INFO> Epoch 430, loss 0.016903, change 0.006646, grad norm 10.635561, lr 0.000100
2021-05-10 12:02:44,537: <INFO> Epoch 435, loss 0.023225, change -0.006322, grad norm 43.992073, lr 0.000100
2021-05-10 12:02:46,626: <INFO> Epoch 440, loss 0.023155, change 0.000070, grad norm 12.395464, lr 0.000100
2021-05-10 12:02:48,690: <INFO> Epoch 445, loss 0.017378, change 0.005778, grad norm 4.598818, lr 0.000100
2021-05-10 12:02:50,767: <INFO> Epoch 450, loss 0.016852, change 0.000526, grad norm 17.883289, lr 0.000100
2021-05-10 12:02:52,844: <INFO> Epoch 455, loss 0.016206, change 0.000646, grad norm 14.703116, lr 0.000100
2021-05-10 12:02:54,920: <INFO> Epoch 460, loss 0.016463, change -0.000257, grad norm 21.148439, lr 0.000100
2021-05-10 12:02:56,998: <INFO> Epoch 465, loss 0.014121, change 0.002341, grad norm 3.697141, lr 0.000100
2021-05-10 12:02:59,077: <INFO> Epoch 470, loss 0.014622, change -0.000501, grad norm 16.870209, lr 0.000100
2021-05-10 12:03:01,155: <INFO> Epoch 475, loss 0.016322, change -0.001700, grad norm 7.472328, lr 0.000100
2021-05-10 12:03:03,230: <INFO> Epoch 480, loss 0.018382, change -0.002060, grad norm 37.275158, lr 0.000100
2021-05-10 12:03:05,313: <INFO> Epoch 485, loss 0.018250, change 0.000132, grad norm 40.286339, lr 0.000100
2021-05-10 12:03:07,387: <INFO> Epoch 490, loss 0.013539, change 0.004711, grad norm 17.591957, lr 0.000100
2021-05-10 12:03:09,464: <INFO> Epoch 495, loss 0.012002, change 0.001538, grad norm 2.491470, lr 0.000100
2021-05-10 12:03:11,144: <INFO> Training model: attempt 2
2021-05-10 12:03:11,252: <INFO> Model: "chuan_et_al"
2021-05-10 12:03:11,252: <INFO> _________________________________________________________________
2021-05-10 12:03:11,252: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-10 12:03:11,253: <INFO> =================================================================
2021-05-10 12:03:11,256: <INFO> conv-1 (Conv2D)              (None, 28, 28, 20)        1520      
2021-05-10 12:03:11,257: <INFO> _________________________________________________________________
2021-05-10 12:03:11,258: <INFO> max-pool-1 (MaxPooling2D)    (None, 14, 14, 20)        0         
2021-05-10 12:03:11,258: <INFO> _________________________________________________________________
2021-05-10 12:03:11,260: <INFO> conv-2 (Conv2D)              (None, 10, 10, 50)        25050     
2021-05-10 12:03:11,260: <INFO> _________________________________________________________________
2021-05-10 12:03:11,261: <INFO> max-pool-2 (MaxPooling2D)    (None, 5, 5, 50)          0         
2021-05-10 12:03:11,261: <INFO> _________________________________________________________________
2021-05-10 12:03:11,262: <INFO> conv-3 (Conv2D)              (None, 2, 2, 500)         400500    
2021-05-10 12:03:11,263: <INFO> _________________________________________________________________
2021-05-10 12:03:11,264: <INFO> conv-3-relu (ReLU)           (None, 2, 2, 500)         0         
2021-05-10 12:03:11,264: <INFO> _________________________________________________________________
2021-05-10 12:03:11,265: <INFO> conv-4 (Conv2D)              (None, 1, 1, 10)          20010     
2021-05-10 12:03:11,266: <INFO> _________________________________________________________________
2021-05-10 12:03:11,266: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-10 12:03:11,267: <INFO> =================================================================
2021-05-10 12:03:11,269: <INFO> Total params: 447,080
2021-05-10 12:03:11,269: <INFO> Trainable params: 447,080
2021-05-10 12:03:11,270: <INFO> Non-trainable params: 0
2021-05-10 12:03:11,270: <INFO> _________________________________________________________________
2021-05-10 12:03:12,486: <INFO> Epoch 0, loss 1.893263, change 1.893263, grad norm 3.736509, lr 0.000100
2021-05-10 12:03:14,538: <INFO> Epoch 5, loss 1.151103, change 0.742160, grad norm 4.650329, lr 0.000100
2021-05-10 12:03:16,602: <INFO> Epoch 10, loss 0.936739, change 0.214363, grad norm 45.696018, lr 0.000100
2021-05-10 12:03:18,670: <INFO> Epoch 15, loss 0.785552, change 0.151188, grad norm 23.421055, lr 0.000100
2021-05-10 12:03:20,736: <INFO> Epoch 20, loss 0.643179, change 0.142373, grad norm 78.185455, lr 0.000100
2021-05-10 12:03:22,811: <INFO> Epoch 25, loss 0.507087, change 0.136092, grad norm 57.975220, lr 0.000100
2021-05-10 12:03:24,884: <INFO> Epoch 30, loss 0.434869, change 0.072218, grad norm 138.250427, lr 0.000100
2021-05-10 12:03:26,953: <INFO> Epoch 35, loss 0.346350, change 0.088519, grad norm 70.095856, lr 0.000100
2021-05-10 12:03:29,035: <INFO> Epoch 40, loss 0.308564, change 0.037786, grad norm 106.071991, lr 0.000100
2021-05-10 12:03:31,199: <INFO> Epoch 45, loss 0.262244, change 0.046320, grad norm 18.828411, lr 0.000100
2021-05-10 12:03:33,240: <INFO> Epoch 50, loss 0.238792, change 0.023452, grad norm 25.368130, lr 0.000100
2021-05-10 12:03:35,263: <INFO> Epoch 55, loss 0.228692, change 0.010100, grad norm 39.497417, lr 0.000100
2021-05-10 12:03:37,558: <INFO> Epoch 60, loss 0.216662, change 0.012030, grad norm 107.273804, lr 0.000100
2021-05-10 12:03:39,825: <INFO> Epoch 65, loss 0.196159, change 0.020502, grad norm 91.835091, lr 0.000100
2021-05-10 12:03:42,129: <INFO> Epoch 70, loss 0.205097, change -0.008938, grad norm 181.890717, lr 0.000100
2021-05-10 12:03:44,228: <INFO> Epoch 75, loss 0.174777, change 0.030320, grad norm 96.937447, lr 0.000100
2021-05-10 12:03:46,258: <INFO> Epoch 80, loss 0.160526, change 0.014251, grad norm 76.448738, lr 0.000100
2021-05-10 12:03:48,430: <INFO> Epoch 85, loss 0.173346, change -0.012820, grad norm 166.947983, lr 0.000100
2021-05-10 12:03:50,501: <INFO> Epoch 90, loss 0.162591, change 0.010755, grad norm 167.886124, lr 0.000100
2021-05-10 12:03:52,604: <INFO> Epoch 95, loss 0.128497, change 0.034094, grad norm 2.289021, lr 0.000100
2021-05-10 12:03:54,650: <INFO> Epoch 100, loss 0.126621, change 0.001876, grad norm 45.425453, lr 0.000100
2021-05-10 12:03:56,661: <INFO> Epoch 105, loss 0.226841, change -0.100219, grad norm 396.568298, lr 0.000100
2021-05-10 12:03:58,680: <INFO> Epoch 110, loss 0.118572, change 0.108269, grad norm 22.577719, lr 0.000100
2021-05-10 12:04:00,698: <INFO> Epoch 115, loss 0.106441, change 0.012130, grad norm 23.591343, lr 0.000100
2021-05-10 12:04:02,711: <INFO> Epoch 120, loss 0.107357, change -0.000916, grad norm 40.552013, lr 0.000100
2021-05-10 12:04:04,717: <INFO> Epoch 125, loss 0.579314, change -0.471957, grad norm 890.005310, lr 0.000100
2021-05-10 12:04:06,734: <INFO> Epoch 130, loss 0.103140, change 0.476174, grad norm 12.887815, lr 0.000100
2021-05-10 12:04:08,749: <INFO> Epoch 135, loss 0.094687, change 0.008453, grad norm 30.837814, lr 0.000100
2021-05-10 12:04:10,753: <INFO> Epoch 140, loss 0.093206, change 0.001481, grad norm 27.387234, lr 0.000100
2021-05-10 12:04:12,762: <INFO> Epoch 145, loss 0.086802, change 0.006404, grad norm 5.568707, lr 0.000100
2021-05-10 12:04:14,760: <INFO> Epoch 150, loss 0.089276, change -0.002474, grad norm 33.156342, lr 0.000100
2021-05-10 12:04:16,773: <INFO> Epoch 155, loss 0.079786, change 0.009490, grad norm 5.995721, lr 0.000100
2021-05-10 12:04:18,765: <INFO> Epoch 160, loss 0.081471, change -0.001685, grad norm 40.053562, lr 0.000100
2021-05-10 12:04:20,772: <INFO> Epoch 165, loss 0.076148, change 0.005324, grad norm 20.107117, lr 0.000100
2021-05-10 12:04:22,775: <INFO> Epoch 170, loss 0.088062, change -0.011915, grad norm 140.429840, lr 0.000100
2021-05-10 12:04:24,779: <INFO> Epoch 175, loss 0.073227, change 0.014835, grad norm 6.139738, lr 0.000100
2021-05-10 12:04:26,792: <INFO> Epoch 180, loss 0.069941, change 0.003286, grad norm 13.357260, lr 0.000100
2021-05-10 12:04:28,803: <INFO> Epoch 185, loss 0.069585, change 0.000356, grad norm 63.239738, lr 0.000100
2021-05-10 12:04:30,822: <INFO> Epoch 190, loss 0.064868, change 0.004717, grad norm 5.881294, lr 0.000100
2021-05-10 12:04:32,829: <INFO> Epoch 195, loss 0.062204, change 0.002664, grad norm 10.485342, lr 0.000100
2021-05-10 12:04:34,840: <INFO> Epoch 200, loss 0.064731, change -0.002526, grad norm 44.056503, lr 0.000100
2021-05-10 12:04:36,852: <INFO> Epoch 205, loss 0.059489, change 0.005242, grad norm 41.961163, lr 0.000100
2021-05-10 12:04:38,861: <INFO> Epoch 210, loss 0.064871, change -0.005382, grad norm 31.042006, lr 0.000100
2021-05-10 12:04:40,886: <INFO> Epoch 215, loss 0.057343, change 0.007527, grad norm 20.202011, lr 0.000100
2021-05-10 12:04:42,900: <INFO> Epoch 220, loss 0.056770, change 0.000574, grad norm 41.406898, lr 0.000100
2021-05-10 12:04:44,913: <INFO> Epoch 225, loss 0.053035, change 0.003734, grad norm 28.632923, lr 0.000100
2021-05-10 12:04:46,920: <INFO> Epoch 230, loss 0.066904, change -0.013869, grad norm 117.803604, lr 0.000100
2021-05-10 12:04:48,930: <INFO> Epoch 235, loss 0.047584, change 0.019321, grad norm 19.482002, lr 0.000100
2021-05-10 12:04:50,945: <INFO> Epoch 240, loss 0.056711, change -0.009127, grad norm 16.121992, lr 0.000100
2021-05-10 12:04:52,950: <INFO> Epoch 245, loss 0.046507, change 0.010204, grad norm 31.695976, lr 0.000100
2021-05-10 12:04:54,960: <INFO> Epoch 250, loss 0.050355, change -0.003848, grad norm 43.937202, lr 0.000100
2021-05-10 12:04:57,000: <INFO> Epoch 255, loss 0.042954, change 0.007401, grad norm 44.458725, lr 0.000100
2021-05-10 12:04:59,006: <INFO> Epoch 260, loss 0.050929, change -0.007975, grad norm 109.333588, lr 0.000100
2021-05-10 12:05:01,005: <INFO> Epoch 265, loss 0.042391, change 0.008538, grad norm 14.961264, lr 0.000100
2021-05-10 12:05:03,022: <INFO> Epoch 270, loss 0.038409, change 0.003982, grad norm 30.218357, lr 0.000100
2021-05-10 12:05:05,026: <INFO> Epoch 275, loss 0.036997, change 0.001412, grad norm 25.396736, lr 0.000100
2021-05-10 12:05:07,043: <INFO> Epoch 280, loss 0.042925, change -0.005928, grad norm 21.848156, lr 0.000100
2021-05-10 12:05:09,057: <INFO> Epoch 285, loss 0.038177, change 0.004748, grad norm 47.516098, lr 0.000100
2021-05-10 12:05:11,080: <INFO> Epoch 290, loss 0.033204, change 0.004973, grad norm 28.093035, lr 0.000100
2021-05-10 12:05:13,096: <INFO> Epoch 295, loss 0.034431, change -0.001227, grad norm 47.119011, lr 0.000100
2021-05-10 12:05:15,107: <INFO> Epoch 300, loss 0.043639, change -0.009208, grad norm 101.567871, lr 0.000100
2021-05-10 12:05:17,115: <INFO> Epoch 305, loss 0.031757, change 0.011882, grad norm 15.317006, lr 0.000100
2021-05-10 12:05:19,122: <INFO> Epoch 310, loss 0.031073, change 0.000684, grad norm 42.113018, lr 0.000100
2021-05-10 12:05:21,131: <INFO> Epoch 315, loss 0.030304, change 0.000769, grad norm 59.013824, lr 0.000100
2021-05-10 12:05:23,143: <INFO> Epoch 320, loss 0.032420, change -0.002116, grad norm 23.389774, lr 0.000100
2021-05-10 12:05:25,157: <INFO> Epoch 325, loss 0.028978, change 0.003442, grad norm 14.212592, lr 0.000100
2021-05-10 12:05:27,169: <INFO> Epoch 330, loss 0.027350, change 0.001628, grad norm 32.814461, lr 0.000100
2021-05-10 12:05:29,176: <INFO> Epoch 335, loss 0.026291, change 0.001059, grad norm 35.167080, lr 0.000100
2021-05-10 12:05:31,182: <INFO> Epoch 340, loss 0.023979, change 0.002312, grad norm 33.340271, lr 0.000100
2021-05-10 12:05:33,190: <INFO> Epoch 345, loss 0.024878, change -0.000899, grad norm 56.720955, lr 0.000100
2021-05-10 12:05:35,194: <INFO> Epoch 350, loss 0.020433, change 0.004445, grad norm 12.886594, lr 0.000100
2021-05-10 12:05:37,206: <INFO> Epoch 355, loss 0.021270, change -0.000837, grad norm 29.152784, lr 0.000100
2021-05-10 12:05:39,207: <INFO> Epoch 360, loss 0.021397, change -0.000127, grad norm 43.140980, lr 0.000100
2021-05-10 12:05:41,215: <INFO> Epoch 365, loss 0.040073, change -0.018676, grad norm 61.143986, lr 0.000100
2021-05-10 12:05:43,211: <INFO> Epoch 370, loss 0.019402, change 0.020671, grad norm 5.783828, lr 0.000100
2021-05-10 12:05:45,214: <INFO> Epoch 375, loss 0.026614, change -0.007212, grad norm 81.082886, lr 0.000100
2021-05-10 12:05:47,218: <INFO> Epoch 380, loss 0.016860, change 0.009754, grad norm 2.790673, lr 0.000100
2021-05-10 12:05:49,227: <INFO> Epoch 385, loss 0.017969, change -0.001109, grad norm 32.254906, lr 0.000100
2021-05-10 12:05:51,230: <INFO> Epoch 390, loss 0.023717, change -0.005747, grad norm 63.130508, lr 0.000100
2021-05-10 12:05:53,245: <INFO> Epoch 395, loss 0.017505, change 0.006211, grad norm 40.867741, lr 0.000100
2021-05-10 12:05:55,251: <INFO> Epoch 400, loss 0.014173, change 0.003332, grad norm 19.330524, lr 0.000100
2021-05-10 12:05:57,264: <INFO> Epoch 405, loss 0.013646, change 0.000527, grad norm 21.353371, lr 0.000100
2021-05-10 12:05:59,270: <INFO> Epoch 410, loss 0.015658, change -0.002012, grad norm 40.977695, lr 0.000100
2021-05-10 12:06:01,274: <INFO> Epoch 415, loss 0.013692, change 0.001966, grad norm 26.732733, lr 0.000100
2021-05-10 12:06:03,289: <INFO> Epoch 420, loss 0.012865, change 0.000827, grad norm 33.257191, lr 0.000100
2021-05-10 12:06:05,305: <INFO> Epoch 425, loss 0.016982, change -0.004117, grad norm 67.454132, lr 0.000100
2021-05-10 12:06:07,309: <INFO> Epoch 430, loss 0.012699, change 0.004283, grad norm 14.581510, lr 0.000100
2021-05-10 12:06:09,317: <INFO> Epoch 435, loss 0.013151, change -0.000452, grad norm 35.731457, lr 0.000100
2021-05-10 12:06:11,326: <INFO> Epoch 440, loss 0.010902, change 0.002249, grad norm 28.170345, lr 0.000100
2021-05-10 12:06:13,337: <INFO> Epoch 445, loss 0.009851, change 0.001051, grad norm 13.554490, lr 0.000100
2021-05-10 12:06:15,346: <INFO> Epoch 450, loss 0.010520, change -0.000669, grad norm 35.832779, lr 0.000100
2021-05-10 12:06:17,358: <INFO> Epoch 455, loss 0.008387, change 0.002133, grad norm 6.293355, lr 0.000100
2021-05-10 12:06:19,360: <INFO> Epoch 460, loss 0.012857, change -0.004470, grad norm 20.967094, lr 0.000100
2021-05-10 12:06:21,365: <INFO> Epoch 465, loss 0.009101, change 0.003756, grad norm 3.175031, lr 0.000100
2021-05-10 12:06:23,375: <INFO> Epoch 470, loss 0.008540, change 0.000561, grad norm 7.052158, lr 0.000100
2021-05-10 12:06:25,384: <INFO> Epoch 475, loss 0.008226, change 0.000314, grad norm 9.860958, lr 0.000100
2021-05-10 12:06:27,392: <INFO> Epoch 480, loss 0.008804, change -0.000578, grad norm 26.139555, lr 0.000100
2021-05-10 12:06:29,391: <INFO> Epoch 485, loss 0.007599, change 0.001206, grad norm 7.688275, lr 0.000100
2021-05-10 12:06:31,402: <INFO> Epoch 490, loss 0.006647, change 0.000952, grad norm 6.377417, lr 0.000100
2021-05-10 12:06:33,421: <INFO> Epoch 495, loss 0.021312, change -0.014665, grad norm 122.664993, lr 0.000100
2021-05-10 12:06:35,627: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-05-10 12:06:35,647: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-05-10 12:06:37,359: <INFO> Assets written to: chuah_et_al\assets
2021-05-10 12:06:37,409: <INFO> Best loss is 0.014255
