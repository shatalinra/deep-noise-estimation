2021-05-10 10:48:41,075: <INFO> Trying model from Chuan et al
2021-05-10 10:48:42,134: <INFO> Training data size 10179
2021-05-10 10:48:42,135: <INFO> Training model: attempt 0
2021-05-10 10:48:42,275: <INFO> Model: "chuan_et_al"
2021-05-10 10:48:42,275: <INFO> _________________________________________________________________
2021-05-10 10:48:42,276: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-10 10:48:42,277: <INFO> =================================================================
2021-05-10 10:48:42,279: <INFO> conv-1 (Conv2D)              (None, 28, 28, 20)        1520      
2021-05-10 10:48:42,279: <INFO> _________________________________________________________________
2021-05-10 10:48:42,280: <INFO> max-pool-1 (MaxPooling2D)    (None, 14, 14, 20)        0         
2021-05-10 10:48:42,281: <INFO> _________________________________________________________________
2021-05-10 10:48:42,282: <INFO> conv-2 (Conv2D)              (None, 10, 10, 50)        25050     
2021-05-10 10:48:42,282: <INFO> _________________________________________________________________
2021-05-10 10:48:42,283: <INFO> max-pool-2 (MaxPooling2D)    (None, 5, 5, 50)          0         
2021-05-10 10:48:42,283: <INFO> _________________________________________________________________
2021-05-10 10:48:42,284: <INFO> conv-3 (Conv2D)              (None, 2, 2, 500)         400500    
2021-05-10 10:48:42,285: <INFO> _________________________________________________________________
2021-05-10 10:48:42,286: <INFO> conv-3-relu (ReLU)           (None, 2, 2, 500)         0         
2021-05-10 10:48:42,288: <INFO> _________________________________________________________________
2021-05-10 10:48:42,289: <INFO> conv-4 (Conv2D)              (None, 1, 1, 10)          20010     
2021-05-10 10:48:42,289: <INFO> _________________________________________________________________
2021-05-10 10:48:42,290: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-10 10:48:42,290: <INFO> =================================================================
2021-05-10 10:48:42,293: <INFO> Total params: 447,080
2021-05-10 10:48:42,293: <INFO> Trainable params: 447,080
2021-05-10 10:48:42,294: <INFO> Non-trainable params: 0
2021-05-10 10:48:42,294: <INFO> _________________________________________________________________
2021-05-10 10:48:46,740: <INFO> Epoch 0, loss 1.491656, change 1.491656, grad norm 5.773324, lr 0.000200
2021-05-10 10:48:48,597: <INFO> Epoch 5, loss 0.637079, change 0.854577, grad norm 60.192898, lr 0.000200
2021-05-10 10:48:50,643: <INFO> Epoch 10, loss 0.380519, change 0.256559, grad norm 53.047684, lr 0.000200
2021-05-10 10:48:52,701: <INFO> Epoch 15, loss 0.232205, change 0.148314, grad norm 38.314259, lr 0.000200
2021-05-10 10:48:54,675: <INFO> Epoch 20, loss 0.182899, change 0.049306, grad norm 60.127106, lr 0.000200
2021-05-10 10:48:56,643: <INFO> Epoch 25, loss 0.159310, change 0.023588, grad norm 93.875725, lr 0.000200
2021-05-10 10:48:58,621: <INFO> Epoch 30, loss 0.120422, change 0.038889, grad norm 74.504097, lr 0.000200
2021-05-10 10:49:00,586: <INFO> Epoch 35, loss 0.138252, change -0.017830, grad norm 103.658630, lr 0.000200
2021-05-10 10:49:02,625: <INFO> Epoch 40, loss 0.155646, change -0.017394, grad norm 143.715622, lr 0.000200
2021-05-10 10:49:04,597: <INFO> Epoch 45, loss 0.076200, change 0.079446, grad norm 42.514553, lr 0.000200
2021-05-10 10:49:06,536: <INFO> Epoch 50, loss 0.041186, change 0.035014, grad norm 1.967196, lr 0.000200
2021-05-10 10:49:08,712: <INFO> Epoch 55, loss 0.066722, change -0.025536, grad norm 54.007526, lr 0.000200
2021-05-10 10:49:11,009: <INFO> Epoch 60, loss 0.033405, change 0.033317, grad norm 4.941184, lr 0.000200
2021-05-10 10:49:13,054: <INFO> Epoch 65, loss 0.037190, change -0.003785, grad norm 39.640282, lr 0.000200
2021-05-10 10:49:15,095: <INFO> Epoch 70, loss 0.034636, change 0.002554, grad norm 43.143154, lr 0.000200
2021-05-10 10:49:17,116: <INFO> Epoch 75, loss 0.025503, change 0.009133, grad norm 24.656826, lr 0.000200
2021-05-10 10:49:19,200: <INFO> Epoch 80, loss 0.037638, change -0.012135, grad norm 29.620888, lr 0.000200
2021-05-10 10:49:21,147: <INFO> Epoch 85, loss 0.017192, change 0.020446, grad norm 9.138115, lr 0.000200
2021-05-10 10:49:23,118: <INFO> Epoch 90, loss 0.018236, change -0.001044, grad norm 4.609907, lr 0.000200
2021-05-10 10:49:25,018: <INFO> Epoch 95, loss 0.017788, change 0.000448, grad norm 1.756660, lr 0.000200
2021-05-10 10:49:26,587: <INFO> Training model: attempt 1
2021-05-10 10:49:26,688: <INFO> Model: "chuan_et_al"
2021-05-10 10:49:26,688: <INFO> _________________________________________________________________
2021-05-10 10:49:26,689: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-10 10:49:26,689: <INFO> =================================================================
2021-05-10 10:49:26,690: <INFO> conv-1 (Conv2D)              (None, 28, 28, 20)        1520      
2021-05-10 10:49:26,691: <INFO> _________________________________________________________________
2021-05-10 10:49:26,692: <INFO> max-pool-1 (MaxPooling2D)    (None, 14, 14, 20)        0         
2021-05-10 10:49:26,692: <INFO> _________________________________________________________________
2021-05-10 10:49:26,693: <INFO> conv-2 (Conv2D)              (None, 10, 10, 50)        25050     
2021-05-10 10:49:26,694: <INFO> _________________________________________________________________
2021-05-10 10:49:26,694: <INFO> max-pool-2 (MaxPooling2D)    (None, 5, 5, 50)          0         
2021-05-10 10:49:26,695: <INFO> _________________________________________________________________
2021-05-10 10:49:26,696: <INFO> conv-3 (Conv2D)              (None, 2, 2, 500)         400500    
2021-05-10 10:49:26,697: <INFO> _________________________________________________________________
2021-05-10 10:49:26,698: <INFO> conv-3-relu (ReLU)           (None, 2, 2, 500)         0         
2021-05-10 10:49:26,698: <INFO> _________________________________________________________________
2021-05-10 10:49:26,700: <INFO> conv-4 (Conv2D)              (None, 1, 1, 10)          20010     
2021-05-10 10:49:26,700: <INFO> _________________________________________________________________
2021-05-10 10:49:26,701: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-10 10:49:26,702: <INFO> =================================================================
2021-05-10 10:49:26,704: <INFO> Total params: 447,080
2021-05-10 10:49:26,705: <INFO> Trainable params: 447,080
2021-05-10 10:49:26,705: <INFO> Non-trainable params: 0
2021-05-10 10:49:26,706: <INFO> _________________________________________________________________
2021-05-10 10:49:27,889: <INFO> Epoch 0, loss 1.450851, change 1.450851, grad norm 4.057454, lr 0.000200
2021-05-10 10:49:29,852: <INFO> Epoch 5, loss 0.713409, change 0.737442, grad norm 99.954025, lr 0.000200
2021-05-10 10:49:31,803: <INFO> Epoch 10, loss 0.378984, change 0.334425, grad norm 32.422054, lr 0.000200
2021-05-10 10:49:33,715: <INFO> Epoch 15, loss 0.243731, change 0.135252, grad norm 32.955940, lr 0.000200
2021-05-10 10:49:35,710: <INFO> Epoch 20, loss 0.167502, change 0.076229, grad norm 36.021488, lr 0.000200
2021-05-10 10:49:37,655: <INFO> Epoch 25, loss 0.125219, change 0.042283, grad norm 16.008366, lr 0.000200
2021-05-10 10:49:39,588: <INFO> Epoch 30, loss 0.109056, change 0.016163, grad norm 23.581472, lr 0.000200
2021-05-10 10:49:41,556: <INFO> Epoch 35, loss 0.129580, change -0.020524, grad norm 116.413445, lr 0.000200
2021-05-10 10:49:43,559: <INFO> Epoch 40, loss 0.071443, change 0.058136, grad norm 28.927803, lr 0.000200
2021-05-10 10:49:45,532: <INFO> Epoch 45, loss 0.087138, change -0.015695, grad norm 36.577976, lr 0.000200
2021-05-10 10:49:47,480: <INFO> Epoch 50, loss 0.063617, change 0.023522, grad norm 63.643990, lr 0.000200
2021-05-10 10:49:49,420: <INFO> Epoch 55, loss 0.043576, change 0.020040, grad norm 5.879015, lr 0.000200
2021-05-10 10:49:51,360: <INFO> Epoch 60, loss 0.054085, change -0.010509, grad norm 55.534023, lr 0.000200
2021-05-10 10:49:53,290: <INFO> Epoch 65, loss 0.036383, change 0.017702, grad norm 14.910516, lr 0.000200
2021-05-10 10:49:55,262: <INFO> Epoch 70, loss 0.040364, change -0.003980, grad norm 65.367065, lr 0.000200
2021-05-10 10:49:57,202: <INFO> Epoch 75, loss 0.031723, change 0.008641, grad norm 48.515896, lr 0.000200
2021-05-10 10:49:59,174: <INFO> Epoch 80, loss 0.046501, change -0.014779, grad norm 25.672199, lr 0.000200
2021-05-10 10:50:01,232: <INFO> Epoch 85, loss 0.023520, change 0.022981, grad norm 18.953533, lr 0.000200
2021-05-10 10:50:03,198: <INFO> Epoch 90, loss 0.019793, change 0.003727, grad norm 6.510746, lr 0.000200
2021-05-10 10:50:05,169: <INFO> Epoch 95, loss 0.019554, change 0.000239, grad norm 28.796015, lr 0.000200
2021-05-10 10:50:06,733: <INFO> Training model: attempt 2
2021-05-10 10:50:06,832: <INFO> Model: "chuan_et_al"
2021-05-10 10:50:06,832: <INFO> _________________________________________________________________
2021-05-10 10:50:06,833: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-10 10:50:06,833: <INFO> =================================================================
2021-05-10 10:50:06,834: <INFO> conv-1 (Conv2D)              (None, 28, 28, 20)        1520      
2021-05-10 10:50:06,834: <INFO> _________________________________________________________________
2021-05-10 10:50:06,835: <INFO> max-pool-1 (MaxPooling2D)    (None, 14, 14, 20)        0         
2021-05-10 10:50:06,835: <INFO> _________________________________________________________________
2021-05-10 10:50:06,837: <INFO> conv-2 (Conv2D)              (None, 10, 10, 50)        25050     
2021-05-10 10:50:06,837: <INFO> _________________________________________________________________
2021-05-10 10:50:06,838: <INFO> max-pool-2 (MaxPooling2D)    (None, 5, 5, 50)          0         
2021-05-10 10:50:06,838: <INFO> _________________________________________________________________
2021-05-10 10:50:06,839: <INFO> conv-3 (Conv2D)              (None, 2, 2, 500)         400500    
2021-05-10 10:50:06,839: <INFO> _________________________________________________________________
2021-05-10 10:50:06,840: <INFO> conv-3-relu (ReLU)           (None, 2, 2, 500)         0         
2021-05-10 10:50:06,841: <INFO> _________________________________________________________________
2021-05-10 10:50:06,842: <INFO> conv-4 (Conv2D)              (None, 1, 1, 10)          20010     
2021-05-10 10:50:06,843: <INFO> _________________________________________________________________
2021-05-10 10:50:06,844: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-10 10:50:06,844: <INFO> =================================================================
2021-05-10 10:50:06,847: <INFO> Total params: 447,080
2021-05-10 10:50:06,847: <INFO> Trainable params: 447,080
2021-05-10 10:50:06,848: <INFO> Non-trainable params: 0
2021-05-10 10:50:06,849: <INFO> _________________________________________________________________
2021-05-10 10:50:08,016: <INFO> Epoch 0, loss 1.537620, change 1.537620, grad norm 18.831697, lr 0.000200
2021-05-10 10:50:09,974: <INFO> Epoch 5, loss 0.793763, change 0.743857, grad norm 72.666466, lr 0.000200
2021-05-10 10:50:11,910: <INFO> Epoch 10, loss 0.464482, change 0.329281, grad norm 3.887442, lr 0.000200
2021-05-10 10:50:13,854: <INFO> Epoch 15, loss 0.313029, change 0.151453, grad norm 28.296961, lr 0.000200
2021-05-10 10:50:15,803: <INFO> Epoch 20, loss 0.286658, change 0.026371, grad norm 139.253372, lr 0.000200
2021-05-10 10:50:17,735: <INFO> Epoch 25, loss 0.155457, change 0.131201, grad norm 36.101269, lr 0.000200
2021-05-10 10:50:19,704: <INFO> Epoch 30, loss 0.154878, change 0.000579, grad norm 50.136673, lr 0.000200
2021-05-10 10:50:21,659: <INFO> Epoch 35, loss 0.098986, change 0.055893, grad norm 16.249546, lr 0.000200
2021-05-10 10:50:23,602: <INFO> Epoch 40, loss 0.095342, change 0.003643, grad norm 93.724602, lr 0.000200
2021-05-10 10:50:25,570: <INFO> Epoch 45, loss 0.053095, change 0.042247, grad norm 11.720650, lr 0.000200
2021-05-10 10:50:27,633: <INFO> Epoch 50, loss 0.069348, change -0.016253, grad norm 54.878582, lr 0.000200
2021-05-10 10:50:29,638: <INFO> Epoch 55, loss 0.070705, change -0.001357, grad norm 133.830399, lr 0.000200
2021-05-10 10:50:31,570: <INFO> Epoch 60, loss 0.035608, change 0.035097, grad norm 32.858742, lr 0.000200
2021-05-10 10:50:33,525: <INFO> Epoch 65, loss 0.057571, change -0.021963, grad norm 85.742287, lr 0.000200
2021-05-10 10:50:35,467: <INFO> Epoch 70, loss 0.048060, change 0.009512, grad norm 69.796265, lr 0.000200
2021-05-10 10:50:37,415: <INFO> Epoch 75, loss 0.029637, change 0.018423, grad norm 16.462616, lr 0.000200
2021-05-10 10:50:39,355: <INFO> Epoch 80, loss 0.025612, change 0.004024, grad norm 10.111801, lr 0.000200
2021-05-10 10:50:41,326: <INFO> Epoch 85, loss 0.023356, change 0.002257, grad norm 16.871033, lr 0.000200
2021-05-10 10:50:43,257: <INFO> Epoch 90, loss 0.070605, change -0.047249, grad norm 128.477509, lr 0.000200
2021-05-10 10:50:45,218: <INFO> Epoch 95, loss 0.440544, change -0.369939, grad norm 651.113403, lr 0.000200
2021-05-10 10:50:47,376: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-05-10 10:50:47,397: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-05-10 10:50:49,218: <INFO> Assets written to: chuah_et_al\assets
2021-05-10 10:50:49,274: <INFO> Best loss is 0.016775
