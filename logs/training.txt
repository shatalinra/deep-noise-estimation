2021-05-21 20:25:25,874: <INFO> Trying simple model
2021-05-21 20:25:27,143: <INFO> Training data size 14940
2021-05-21 20:25:27,144: <INFO> Training model: attempt 0
2021-05-21 20:25:27,329: <INFO> Model: "simple"
2021-05-21 20:25:27,330: <INFO> _________________________________________________________________
2021-05-21 20:25:27,332: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-21 20:25:27,333: <INFO> =================================================================
2021-05-21 20:25:27,336: <INFO> conv-1 (Conv2D)              (None, 16, 16, 8)         104       
2021-05-21 20:25:27,336: <INFO> _________________________________________________________________
2021-05-21 20:25:27,337: <INFO> conv-1-leaky (LeakyReLU)     (None, 16, 16, 8)         0         
2021-05-21 20:25:27,338: <INFO> _________________________________________________________________
2021-05-21 20:25:27,340: <INFO> conv-2 (Conv2D)              (None, 8, 8, 16)          528       
2021-05-21 20:25:27,340: <INFO> _________________________________________________________________
2021-05-21 20:25:27,342: <INFO> conv-2-leaky (LeakyReLU)     (None, 8, 8, 16)          0         
2021-05-21 20:25:27,342: <INFO> _________________________________________________________________
2021-05-21 20:25:27,343: <INFO> conv-3 (Conv2D)              (None, 4, 4, 16)          1040      
2021-05-21 20:25:27,344: <INFO> _________________________________________________________________
2021-05-21 20:25:27,345: <INFO> conv-3-leaky (LeakyReLU)     (None, 4, 4, 16)          0         
2021-05-21 20:25:27,346: <INFO> _________________________________________________________________
2021-05-21 20:25:27,347: <INFO> conv-4 (Conv2D)              (None, 2, 2, 1)           65        
2021-05-21 20:25:27,348: <INFO> _________________________________________________________________
2021-05-21 20:25:27,349: <INFO> conv-4-leaky (LeakyReLU)     (None, 2, 2, 1)           0         
2021-05-21 20:25:27,349: <INFO> _________________________________________________________________
2021-05-21 20:25:27,351: <INFO> conv-5 (Conv2D)              (None, 1, 1, 10)          50        
2021-05-21 20:25:27,351: <INFO> _________________________________________________________________
2021-05-21 20:25:27,352: <INFO> conv-5-leaky (LeakyReLU)     (None, 1, 1, 10)          0         
2021-05-21 20:25:27,353: <INFO> _________________________________________________________________
2021-05-21 20:25:27,353: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-21 20:25:27,356: <INFO> =================================================================
2021-05-21 20:25:27,360: <INFO> Total params: 1,787
2021-05-21 20:25:27,360: <INFO> Trainable params: 1,787
2021-05-21 20:25:27,361: <INFO> Non-trainable params: 0
2021-05-21 20:25:27,361: <INFO> _________________________________________________________________
2021-05-21 20:25:31,976: <INFO> Epoch 0, loss 2.061239, change 2.061239, grad norm 3.823128, lr 0.004000
2021-05-21 20:25:34,950: <INFO> Epoch 5, loss 1.160037, change 0.901202, grad norm 29.151262, lr 0.004000
2021-05-21 20:25:37,878: <INFO> Epoch 10, loss 0.942612, change 0.217425, grad norm 10.852516, lr 0.004000
2021-05-21 20:25:40,771: <INFO> Epoch 15, loss 0.877235, change 0.065377, grad norm 39.583046, lr 0.004000
2021-05-21 20:25:43,673: <INFO> Epoch 20, loss 0.731018, change 0.146217, grad norm 19.894432, lr 0.004000
2021-05-21 20:25:46,489: <INFO> Epoch 25, loss 0.649176, change 0.081842, grad norm 20.396862, lr 0.004000
2021-05-21 20:25:49,373: <INFO> Epoch 30, loss 0.611951, change 0.037225, grad norm 36.133533, lr 0.004000
2021-05-21 20:25:52,214: <INFO> Epoch 35, loss 0.512612, change 0.099339, grad norm 15.290470, lr 0.004000
2021-05-21 20:25:55,091: <INFO> Epoch 40, loss 0.460643, change 0.051969, grad norm 30.790386, lr 0.004000
2021-05-21 20:25:58,029: <INFO> Epoch 45, loss 0.414864, change 0.045779, grad norm 14.959435, lr 0.004000
2021-05-21 20:26:00,869: <INFO> Epoch 50, loss 0.374566, change 0.040299, grad norm 7.008777, lr 0.004000
2021-05-21 20:26:03,734: <INFO> Epoch 55, loss 0.335155, change 0.039410, grad norm 19.782198, lr 0.004000
2021-05-21 20:26:06,642: <INFO> Epoch 60, loss 0.346110, change -0.010955, grad norm 30.440380, lr 0.004000
2021-05-21 20:26:09,552: <INFO> Epoch 65, loss 0.310699, change 0.035412, grad norm 48.880478, lr 0.004000
2021-05-21 20:26:12,483: <INFO> Epoch 70, loss 0.266937, change 0.043761, grad norm 27.411583, lr 0.004000
2021-05-21 20:26:15,407: <INFO> Epoch 75, loss 0.266340, change 0.000597, grad norm 34.797817, lr 0.004000
2021-05-21 20:26:18,339: <INFO> Epoch 80, loss 0.225292, change 0.041048, grad norm 7.302020, lr 0.004000
2021-05-21 20:26:21,286: <INFO> Epoch 85, loss 0.229823, change -0.004530, grad norm 36.039734, lr 0.004000
2021-05-21 20:26:24,218: <INFO> Epoch 90, loss 0.223068, change 0.006755, grad norm 40.577682, lr 0.004000
2021-05-21 20:26:27,140: <INFO> Epoch 95, loss 0.208900, change 0.014168, grad norm 42.516373, lr 0.004000
2021-05-21 20:26:30,049: <INFO> Epoch 100, loss 0.172128, change 0.036772, grad norm 16.618864, lr 0.004000
2021-05-21 20:26:32,930: <INFO> Epoch 105, loss 0.189121, change -0.016994, grad norm 43.747585, lr 0.004000
2021-05-21 20:26:35,839: <INFO> Epoch 110, loss 0.173878, change 0.015243, grad norm 16.455896, lr 0.004000
2021-05-21 20:26:38,750: <INFO> Epoch 115, loss 0.149692, change 0.024187, grad norm 7.155539, lr 0.004000
2021-05-21 20:26:41,668: <INFO> Epoch 120, loss 0.153772, change -0.004080, grad norm 15.502212, lr 0.004000
2021-05-21 20:26:44,589: <INFO> Epoch 125, loss 0.138532, change 0.015240, grad norm 3.471071, lr 0.004000
2021-05-21 20:26:47,479: <INFO> Epoch 130, loss 0.135449, change 0.003083, grad norm 20.412312, lr 0.004000
2021-05-21 20:26:50,464: <INFO> Epoch 135, loss 0.134882, change 0.000567, grad norm 17.464973, lr 0.004000
2021-05-21 20:26:53,370: <INFO> Epoch 140, loss 0.151178, change -0.016296, grad norm 44.591755, lr 0.004000
2021-05-21 20:26:56,253: <INFO> Epoch 145, loss 0.111526, change 0.039652, grad norm 2.191800, lr 0.004000
2021-05-21 20:26:59,167: <INFO> Epoch 150, loss 0.106774, change 0.004752, grad norm 4.219102, lr 0.004000
2021-05-21 20:27:02,145: <INFO> Epoch 155, loss 0.126821, change -0.020048, grad norm 28.602472, lr 0.004000
2021-05-21 20:27:05,087: <INFO> Epoch 160, loss 0.109286, change 0.017535, grad norm 23.119961, lr 0.004000
2021-05-21 20:27:08,001: <INFO> Epoch 165, loss 0.133713, change -0.024427, grad norm 15.512240, lr 0.004000
2021-05-21 20:27:10,887: <INFO> Epoch 170, loss 0.138500, change -0.004787, grad norm 37.870419, lr 0.004000
2021-05-21 20:27:13,709: <INFO> Epoch 175, loss 0.098096, change 0.040405, grad norm 14.416163, lr 0.004000
2021-05-21 20:27:16,501: <INFO> Epoch 180, loss 0.084299, change 0.013797, grad norm 4.190355, lr 0.004000
2021-05-21 20:27:19,293: <INFO> Epoch 185, loss 0.103830, change -0.019531, grad norm 23.439457, lr 0.004000
2021-05-21 20:27:22,102: <INFO> Epoch 190, loss 0.101409, change 0.002420, grad norm 17.123285, lr 0.004000
2021-05-21 20:27:24,902: <INFO> Epoch 195, loss 0.091357, change 0.010052, grad norm 5.534286, lr 0.004000
2021-05-21 20:27:27,801: <INFO> Epoch 200, loss 0.078454, change 0.012903, grad norm 10.667960, lr 0.004000
2021-05-21 20:27:30,725: <INFO> Epoch 205, loss 0.150427, change -0.071973, grad norm 40.558044, lr 0.004000
2021-05-21 20:27:33,649: <INFO> Epoch 210, loss 0.083578, change 0.066848, grad norm 11.591691, lr 0.004000
2021-05-21 20:27:36,624: <INFO> Epoch 215, loss 0.087271, change -0.003693, grad norm 12.103687, lr 0.004000
2021-05-21 20:27:39,577: <INFO> Epoch 220, loss 0.199462, change -0.112191, grad norm 67.047874, lr 0.004000
2021-05-21 20:27:42,476: <INFO> Epoch 225, loss 0.065774, change 0.133687, grad norm 9.514037, lr 0.004000
2021-05-21 20:27:45,402: <INFO> Epoch 230, loss 0.065901, change -0.000126, grad norm 4.400174, lr 0.004000
2021-05-21 20:27:48,310: <INFO> Epoch 235, loss 0.069749, change -0.003848, grad norm 9.810773, lr 0.004000
2021-05-21 20:27:51,218: <INFO> Epoch 240, loss 0.064366, change 0.005383, grad norm 1.980161, lr 0.004000
2021-05-21 20:27:54,110: <INFO> Epoch 245, loss 0.090400, change -0.026035, grad norm 22.298220, lr 0.004000
2021-05-21 20:27:56,993: <INFO> Epoch 250, loss 0.077244, change 0.013156, grad norm 18.435129, lr 0.004000
2021-05-21 20:27:59,845: <INFO> Epoch 255, loss 0.062207, change 0.015037, grad norm 8.682319, lr 0.004000
2021-05-21 20:28:02,728: <INFO> Epoch 260, loss 0.068554, change -0.006347, grad norm 14.599645, lr 0.004000
2021-05-21 20:28:05,613: <INFO> Epoch 265, loss 0.053199, change 0.015355, grad norm 1.193147, lr 0.004000
2021-05-21 20:28:08,519: <INFO> Epoch 270, loss 0.053151, change 0.000048, grad norm 1.786635, lr 0.004000
2021-05-21 20:28:11,403: <INFO> Epoch 275, loss 0.061510, change -0.008359, grad norm 7.681202, lr 0.004000
2021-05-21 20:28:14,248: <INFO> Epoch 280, loss 0.058537, change 0.002972, grad norm 11.281429, lr 0.004000
2021-05-21 20:28:17,135: <INFO> Epoch 285, loss 0.162504, change -0.103967, grad norm 65.470078, lr 0.004000
2021-05-21 20:28:20,009: <INFO> Epoch 290, loss 0.072867, change 0.089637, grad norm 22.293797, lr 0.004000
2021-05-21 20:28:22,905: <INFO> Epoch 295, loss 0.063869, change 0.008998, grad norm 18.037678, lr 0.004000
2021-05-21 20:28:25,814: <INFO> Epoch 300, loss 0.048827, change 0.015041, grad norm 3.600609, lr 0.004000
2021-05-21 20:28:28,678: <INFO> Epoch 305, loss 0.047949, change 0.000879, grad norm 7.136634, lr 0.004000
2021-05-21 20:28:31,553: <INFO> Epoch 310, loss 0.048196, change -0.000247, grad norm 4.299530, lr 0.004000
2021-05-21 20:28:34,421: <INFO> Epoch 315, loss 0.045248, change 0.002948, grad norm 5.599214, lr 0.004000
2021-05-21 20:28:37,336: <INFO> Epoch 320, loss 0.051899, change -0.006651, grad norm 6.579473, lr 0.004000
2021-05-21 20:28:40,225: <INFO> Epoch 325, loss 0.055742, change -0.003844, grad norm 10.193707, lr 0.004000
2021-05-21 20:28:43,110: <INFO> Epoch 330, loss 0.052639, change 0.003103, grad norm 9.129754, lr 0.004000
2021-05-21 20:28:46,009: <INFO> Epoch 335, loss 0.049132, change 0.003508, grad norm 6.103090, lr 0.004000
2021-05-21 20:28:48,896: <INFO> Epoch 340, loss 0.044310, change 0.004822, grad norm 8.926326, lr 0.004000
2021-05-21 20:28:51,750: <INFO> Epoch 345, loss 0.057012, change -0.012702, grad norm 13.665872, lr 0.004000
2021-05-21 20:28:54,619: <INFO> Epoch 350, loss 0.047057, change 0.009955, grad norm 1.693002, lr 0.004000
2021-05-21 20:28:57,502: <INFO> Epoch 355, loss 0.133397, change -0.086340, grad norm 42.848366, lr 0.004000
2021-05-21 20:29:00,357: <INFO> Epoch 360, loss 0.098900, change 0.034497, grad norm 9.175164, lr 0.004000
2021-05-21 20:29:03,234: <INFO> Epoch 365, loss 0.047833, change 0.051067, grad norm 10.804132, lr 0.004000
2021-05-21 20:29:06,114: <INFO> Epoch 370, loss 0.043280, change 0.004554, grad norm 5.666152, lr 0.004000
2021-05-21 20:29:08,996: <INFO> Epoch 375, loss 0.065842, change -0.022563, grad norm 21.362188, lr 0.004000
2021-05-21 20:29:11,865: <INFO> Epoch 380, loss 0.040454, change 0.025388, grad norm 8.286500, lr 0.004000
2021-05-21 20:29:14,715: <INFO> Epoch 385, loss 0.057315, change -0.016860, grad norm 19.565382, lr 0.004000
2021-05-21 20:29:17,611: <INFO> Epoch 390, loss 0.044996, change 0.012319, grad norm 9.810158, lr 0.004000
2021-05-21 20:29:20,567: <INFO> Epoch 395, loss 0.043439, change 0.001557, grad norm 1.236222, lr 0.004000
2021-05-21 20:29:22,865: <INFO> Training model: attempt 1
2021-05-21 20:29:23,008: <INFO> Model: "simple"
2021-05-21 20:29:23,009: <INFO> _________________________________________________________________
2021-05-21 20:29:23,009: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-21 20:29:23,010: <INFO> =================================================================
2021-05-21 20:29:23,014: <INFO> conv-1 (Conv2D)              (None, 16, 16, 8)         104       
2021-05-21 20:29:23,014: <INFO> _________________________________________________________________
2021-05-21 20:29:23,016: <INFO> conv-1-leaky (LeakyReLU)     (None, 16, 16, 8)         0         
2021-05-21 20:29:23,016: <INFO> _________________________________________________________________
2021-05-21 20:29:23,018: <INFO> conv-2 (Conv2D)              (None, 8, 8, 16)          528       
2021-05-21 20:29:23,018: <INFO> _________________________________________________________________
2021-05-21 20:29:23,019: <INFO> conv-2-leaky (LeakyReLU)     (None, 8, 8, 16)          0         
2021-05-21 20:29:23,019: <INFO> _________________________________________________________________
2021-05-21 20:29:23,021: <INFO> conv-3 (Conv2D)              (None, 4, 4, 16)          1040      
2021-05-21 20:29:23,021: <INFO> _________________________________________________________________
2021-05-21 20:29:23,023: <INFO> conv-3-leaky (LeakyReLU)     (None, 4, 4, 16)          0         
2021-05-21 20:29:23,023: <INFO> _________________________________________________________________
2021-05-21 20:29:23,024: <INFO> conv-4 (Conv2D)              (None, 2, 2, 1)           65        
2021-05-21 20:29:23,025: <INFO> _________________________________________________________________
2021-05-21 20:29:23,026: <INFO> conv-4-leaky (LeakyReLU)     (None, 2, 2, 1)           0         
2021-05-21 20:29:23,026: <INFO> _________________________________________________________________
2021-05-21 20:29:23,029: <INFO> conv-5 (Conv2D)              (None, 1, 1, 10)          50        
2021-05-21 20:29:23,030: <INFO> _________________________________________________________________
2021-05-21 20:29:23,031: <INFO> conv-5-leaky (LeakyReLU)     (None, 1, 1, 10)          0         
2021-05-21 20:29:23,032: <INFO> _________________________________________________________________
2021-05-21 20:29:23,033: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-21 20:29:23,033: <INFO> =================================================================
2021-05-21 20:29:23,036: <INFO> Total params: 1,787
2021-05-21 20:29:23,036: <INFO> Trainable params: 1,787
2021-05-21 20:29:23,037: <INFO> Non-trainable params: 0
2021-05-21 20:29:23,037: <INFO> _________________________________________________________________
2021-05-21 20:29:24,700: <INFO> Epoch 0, loss 2.211409, change 2.211409, grad norm 0.169696, lr 0.004000
2021-05-21 20:29:27,583: <INFO> Epoch 5, loss 1.156066, change 1.055343, grad norm 19.489920, lr 0.004000
2021-05-21 20:29:30,552: <INFO> Epoch 10, loss 0.815323, change 0.340742, grad norm 6.658420, lr 0.004000
2021-05-21 20:29:33,423: <INFO> Epoch 15, loss 0.706745, change 0.108579, grad norm 32.599930, lr 0.004000
2021-05-21 20:29:36,568: <INFO> Epoch 20, loss 0.613164, change 0.093581, grad norm 35.828571, lr 0.004000
2021-05-21 20:29:39,448: <INFO> Epoch 25, loss 0.541758, change 0.071406, grad norm 3.479569, lr 0.004000
2021-05-21 20:29:42,934: <INFO> Epoch 30, loss 0.476461, change 0.065297, grad norm 8.491373, lr 0.004000
2021-05-21 20:29:46,022: <INFO> Epoch 35, loss 0.627481, change -0.151020, grad norm 137.086761, lr 0.004000
2021-05-21 20:29:49,418: <INFO> Epoch 40, loss 0.353720, change 0.273761, grad norm 14.637013, lr 0.004000
2021-05-21 20:29:52,330: <INFO> Epoch 45, loss 0.332305, change 0.021415, grad norm 29.646723, lr 0.004000
2021-05-21 20:29:55,268: <INFO> Epoch 50, loss 0.438441, change -0.106136, grad norm 91.181610, lr 0.004000
2021-05-21 20:29:58,178: <INFO> Epoch 55, loss 0.266760, change 0.171681, grad norm 22.766455, lr 0.004000
2021-05-21 20:30:01,163: <INFO> Epoch 60, loss 0.245101, change 0.021658, grad norm 10.669074, lr 0.004000
2021-05-21 20:30:04,111: <INFO> Epoch 65, loss 0.229168, change 0.015933, grad norm 20.284174, lr 0.004000
2021-05-21 20:30:07,022: <INFO> Epoch 70, loss 0.321244, change -0.092076, grad norm 84.243645, lr 0.004000
2021-05-21 20:30:10,002: <INFO> Epoch 75, loss 0.197031, change 0.124213, grad norm 16.665604, lr 0.004000
2021-05-21 20:30:12,932: <INFO> Epoch 80, loss 0.173933, change 0.023098, grad norm 8.559733, lr 0.004000
2021-05-21 20:30:15,848: <INFO> Epoch 85, loss 0.191919, change -0.017986, grad norm 12.580808, lr 0.004000
2021-05-21 20:30:18,809: <INFO> Epoch 90, loss 0.202523, change -0.010604, grad norm 34.406796, lr 0.004000
2021-05-21 20:30:21,719: <INFO> Epoch 95, loss 0.156200, change 0.046323, grad norm 9.981642, lr 0.004000
2021-05-21 20:30:24,683: <INFO> Epoch 100, loss 0.183428, change -0.027228, grad norm 30.886715, lr 0.004000
2021-05-21 20:30:27,662: <INFO> Epoch 105, loss 0.160450, change 0.022978, grad norm 13.287427, lr 0.004000
2021-05-21 20:30:30,594: <INFO> Epoch 110, loss 0.146371, change 0.014079, grad norm 27.532606, lr 0.004000
2021-05-21 20:30:33,500: <INFO> Epoch 115, loss 0.168986, change -0.022615, grad norm 35.582539, lr 0.004000
2021-05-21 20:30:36,459: <INFO> Epoch 120, loss 0.130930, change 0.038056, grad norm 6.080116, lr 0.004000
2021-05-21 20:30:39,385: <INFO> Epoch 125, loss 0.193859, change -0.062928, grad norm 50.911442, lr 0.004000
2021-05-21 20:30:42,364: <INFO> Epoch 130, loss 0.130353, change 0.063506, grad norm 5.363140, lr 0.004000
2021-05-21 20:30:45,327: <INFO> Epoch 135, loss 0.133771, change -0.003418, grad norm 29.313248, lr 0.004000
2021-05-21 20:30:48,266: <INFO> Epoch 140, loss 0.111538, change 0.022233, grad norm 8.997142, lr 0.004000
2021-05-21 20:30:51,214: <INFO> Epoch 145, loss 0.126384, change -0.014846, grad norm 6.363490, lr 0.004000
2021-05-21 20:30:54,084: <INFO> Epoch 150, loss 0.109846, change 0.016538, grad norm 15.141579, lr 0.004000
2021-05-21 20:30:57,050: <INFO> Epoch 155, loss 0.109387, change 0.000459, grad norm 9.955825, lr 0.004000
2021-05-21 20:30:59,978: <INFO> Epoch 160, loss 0.128604, change -0.019217, grad norm 36.205162, lr 0.004000
2021-05-21 20:31:02,889: <INFO> Epoch 165, loss 0.098639, change 0.029965, grad norm 8.344836, lr 0.004000
2021-05-21 20:31:05,921: <INFO> Epoch 170, loss 0.095193, change 0.003446, grad norm 14.664808, lr 0.004000
2021-05-21 20:31:08,868: <INFO> Epoch 175, loss 0.089960, change 0.005232, grad norm 8.118608, lr 0.004000
2021-05-21 20:31:11,807: <INFO> Epoch 180, loss 0.091048, change -0.001088, grad norm 9.602527, lr 0.004000
2021-05-21 20:31:14,737: <INFO> Epoch 185, loss 0.162720, change -0.071672, grad norm 49.344887, lr 0.004000
2021-05-21 20:31:17,660: <INFO> Epoch 190, loss 0.088487, change 0.074233, grad norm 15.364951, lr 0.004000
2021-05-21 20:31:20,682: <INFO> Epoch 195, loss 0.088908, change -0.000421, grad norm 15.700544, lr 0.004000
2021-05-21 20:31:23,655: <INFO> Epoch 200, loss 0.075191, change 0.013717, grad norm 2.700710, lr 0.004000
2021-05-21 20:31:26,652: <INFO> Epoch 205, loss 0.080654, change -0.005464, grad norm 3.500502, lr 0.004000
2021-05-21 20:31:29,567: <INFO> Epoch 210, loss 0.076800, change 0.003855, grad norm 6.563411, lr 0.004000
2021-05-21 20:31:32,499: <INFO> Epoch 215, loss 0.087548, change -0.010748, grad norm 20.738865, lr 0.004000
2021-05-21 20:31:35,516: <INFO> Epoch 220, loss 0.074524, change 0.013024, grad norm 4.768850, lr 0.004000
2021-05-21 20:31:38,435: <INFO> Epoch 225, loss 0.071258, change 0.003266, grad norm 10.006174, lr 0.004000
2021-05-21 20:31:41,349: <INFO> Epoch 230, loss 0.123955, change -0.052698, grad norm 16.338547, lr 0.004000
2021-05-21 20:31:44,269: <INFO> Epoch 235, loss 0.152843, change -0.028888, grad norm 46.966877, lr 0.004000
2021-05-21 20:31:47,197: <INFO> Epoch 240, loss 0.065896, change 0.086947, grad norm 1.957011, lr 0.004000
2021-05-21 20:31:50,198: <INFO> Epoch 245, loss 0.174213, change -0.108317, grad norm 40.800072, lr 0.004000
2021-05-21 20:31:53,130: <INFO> Epoch 250, loss 0.095796, change 0.078417, grad norm 23.134249, lr 0.004000
2021-05-21 20:31:56,123: <INFO> Epoch 255, loss 0.058843, change 0.036953, grad norm 2.396252, lr 0.004000
2021-05-21 20:31:59,061: <INFO> Epoch 260, loss 0.063175, change -0.004332, grad norm 4.499518, lr 0.004000
2021-05-21 20:32:01,946: <INFO> Epoch 265, loss 0.072873, change -0.009699, grad norm 14.033273, lr 0.004000
2021-05-21 20:32:04,854: <INFO> Epoch 270, loss 0.059764, change 0.013109, grad norm 6.930981, lr 0.004000
2021-05-21 20:32:07,810: <INFO> Epoch 275, loss 0.241488, change -0.181724, grad norm 9.991147, lr 0.004000
2021-05-21 20:32:10,713: <INFO> Epoch 280, loss 0.070638, change 0.170850, grad norm 20.898190, lr 0.004000
2021-05-21 20:32:13,666: <INFO> Epoch 285, loss 0.062285, change 0.008353, grad norm 7.471767, lr 0.004000
2021-05-21 20:32:16,564: <INFO> Epoch 290, loss 0.063032, change -0.000747, grad norm 2.606279, lr 0.004000
2021-05-21 20:32:19,499: <INFO> Epoch 295, loss 0.064491, change -0.001459, grad norm 16.871563, lr 0.004000
2021-05-21 20:32:22,405: <INFO> Epoch 300, loss 0.275625, change -0.211134, grad norm 56.455132, lr 0.004000
2021-05-21 20:32:25,384: <INFO> Epoch 305, loss 0.050671, change 0.224954, grad norm 9.851632, lr 0.004000
2021-05-21 20:32:28,337: <INFO> Epoch 310, loss 0.063294, change -0.012623, grad norm 16.935444, lr 0.004000
2021-05-21 20:32:31,273: <INFO> Epoch 315, loss 0.057339, change 0.005955, grad norm 10.586446, lr 0.004000
2021-05-21 20:32:34,171: <INFO> Epoch 320, loss 0.051409, change 0.005929, grad norm 11.540932, lr 0.004000
2021-05-21 20:32:37,102: <INFO> Epoch 325, loss 0.047471, change 0.003938, grad norm 7.558921, lr 0.004000
2021-05-21 20:32:40,022: <INFO> Epoch 330, loss 0.084258, change -0.036787, grad norm 30.169724, lr 0.004000
2021-05-21 20:32:42,933: <INFO> Epoch 335, loss 0.051541, change 0.032717, grad norm 10.657599, lr 0.004000
2021-05-21 20:32:45,931: <INFO> Epoch 340, loss 0.046471, change 0.005070, grad norm 2.344977, lr 0.004000
2021-05-21 20:32:48,864: <INFO> Epoch 345, loss 0.042041, change 0.004430, grad norm 2.601979, lr 0.004000
2021-05-21 20:32:51,813: <INFO> Epoch 350, loss 0.051288, change -0.009247, grad norm 9.579097, lr 0.004000
2021-05-21 20:32:54,755: <INFO> Epoch 355, loss 0.046714, change 0.004575, grad norm 7.931155, lr 0.004000
2021-05-21 20:32:57,779: <INFO> Epoch 360, loss 0.074327, change -0.027614, grad norm 29.252930, lr 0.004000
2021-05-21 20:33:00,795: <INFO> Epoch 365, loss 0.057500, change 0.016828, grad norm 14.896281, lr 0.004000
2021-05-21 20:33:03,738: <INFO> Epoch 370, loss 0.041588, change 0.015912, grad norm 2.492847, lr 0.004000
2021-05-21 20:33:06,668: <INFO> Epoch 375, loss 0.055787, change -0.014199, grad norm 12.754212, lr 0.004000
2021-05-21 20:33:09,589: <INFO> Epoch 380, loss 0.072378, change -0.016591, grad norm 10.057013, lr 0.004000
2021-05-21 20:33:12,530: <INFO> Epoch 385, loss 0.047036, change 0.025342, grad norm 6.969055, lr 0.004000
2021-05-21 20:33:15,451: <INFO> Epoch 390, loss 0.051029, change -0.003992, grad norm 11.710716, lr 0.004000
2021-05-21 20:33:18,464: <INFO> Epoch 395, loss 0.048032, change 0.002997, grad norm 8.024032, lr 0.004000
2021-05-21 20:33:20,823: <INFO> Training model: attempt 2
2021-05-21 20:33:20,977: <INFO> Model: "simple"
2021-05-21 20:33:20,977: <INFO> _________________________________________________________________
2021-05-21 20:33:20,978: <INFO> Layer (type)                 Output Shape              Param #   
2021-05-21 20:33:20,978: <INFO> =================================================================
2021-05-21 20:33:20,980: <INFO> conv-1 (Conv2D)              (None, 16, 16, 8)         104       
2021-05-21 20:33:20,980: <INFO> _________________________________________________________________
2021-05-21 20:33:20,982: <INFO> conv-1-leaky (LeakyReLU)     (None, 16, 16, 8)         0         
2021-05-21 20:33:20,982: <INFO> _________________________________________________________________
2021-05-21 20:33:20,983: <INFO> conv-2 (Conv2D)              (None, 8, 8, 16)          528       
2021-05-21 20:33:20,984: <INFO> _________________________________________________________________
2021-05-21 20:33:20,985: <INFO> conv-2-leaky (LeakyReLU)     (None, 8, 8, 16)          0         
2021-05-21 20:33:20,985: <INFO> _________________________________________________________________
2021-05-21 20:33:20,987: <INFO> conv-3 (Conv2D)              (None, 4, 4, 16)          1040      
2021-05-21 20:33:20,987: <INFO> _________________________________________________________________
2021-05-21 20:33:20,988: <INFO> conv-3-leaky (LeakyReLU)     (None, 4, 4, 16)          0         
2021-05-21 20:33:20,988: <INFO> _________________________________________________________________
2021-05-21 20:33:20,990: <INFO> conv-4 (Conv2D)              (None, 2, 2, 1)           65        
2021-05-21 20:33:20,991: <INFO> _________________________________________________________________
2021-05-21 20:33:20,993: <INFO> conv-4-leaky (LeakyReLU)     (None, 2, 2, 1)           0         
2021-05-21 20:33:20,993: <INFO> _________________________________________________________________
2021-05-21 20:33:20,995: <INFO> conv-5 (Conv2D)              (None, 1, 1, 10)          50        
2021-05-21 20:33:20,995: <INFO> _________________________________________________________________
2021-05-21 20:33:20,997: <INFO> conv-5-leaky (LeakyReLU)     (None, 1, 1, 10)          0         
2021-05-21 20:33:20,997: <INFO> _________________________________________________________________
2021-05-21 20:33:20,998: <INFO> conv-4-softmax (Softmax)     (None, 1, 1, 10)          0         
2021-05-21 20:33:20,999: <INFO> =================================================================
2021-05-21 20:33:21,002: <INFO> Total params: 1,787
2021-05-21 20:33:21,002: <INFO> Trainable params: 1,787
2021-05-21 20:33:21,003: <INFO> Non-trainable params: 0
2021-05-21 20:33:21,004: <INFO> _________________________________________________________________
2021-05-21 20:33:22,796: <INFO> Epoch 0, loss 2.207252, change 2.207252, grad norm 0.395838, lr 0.004000
2021-05-21 20:33:25,712: <INFO> Epoch 5, loss 2.200047, change 0.007204, grad norm 0.253030, lr 0.004000
2021-05-21 20:33:28,565: <INFO> Epoch 10, loss 1.397108, change 0.802940, grad norm 6.355425, lr 0.004000
2021-05-21 20:33:31,523: <INFO> Epoch 15, loss 0.858336, change 0.538771, grad norm 9.026750, lr 0.004000
2021-05-21 20:33:34,417: <INFO> Epoch 20, loss 0.892271, change -0.033935, grad norm 32.017826, lr 0.004000
2021-05-21 20:33:37,318: <INFO> Epoch 25, loss 0.555475, change 0.336796, grad norm 5.692297, lr 0.004000
2021-05-21 20:33:40,215: <INFO> Epoch 30, loss 0.562863, change -0.007388, grad norm 38.335091, lr 0.004000
2021-05-21 20:33:43,285: <INFO> Epoch 35, loss 0.487752, change 0.075111, grad norm 36.075035, lr 0.004000
2021-05-21 20:33:46,197: <INFO> Epoch 40, loss 0.400399, change 0.087352, grad norm 9.095645, lr 0.004000
2021-05-21 20:33:49,106: <INFO> Epoch 45, loss 0.352223, change 0.048176, grad norm 12.815078, lr 0.004000
2021-05-21 20:33:51,997: <INFO> Epoch 50, loss 0.420612, change -0.068389, grad norm 36.915142, lr 0.004000
2021-05-21 20:33:54,881: <INFO> Epoch 55, loss 0.397072, change 0.023540, grad norm 42.284992, lr 0.004000
2021-05-21 20:33:57,854: <INFO> Epoch 60, loss 0.262722, change 0.134350, grad norm 7.286968, lr 0.004000
2021-05-21 20:34:00,903: <INFO> Epoch 65, loss 0.260396, change 0.002326, grad norm 10.044622, lr 0.004000
2021-05-21 20:34:03,888: <INFO> Epoch 70, loss 0.245634, change 0.014762, grad norm 13.103232, lr 0.004000
2021-05-21 20:34:06,821: <INFO> Epoch 75, loss 0.234452, change 0.011181, grad norm 10.563289, lr 0.004000
2021-05-21 20:34:09,756: <INFO> Epoch 80, loss 0.208224, change 0.026228, grad norm 3.555544, lr 0.004000
2021-05-21 20:34:12,768: <INFO> Epoch 85, loss 0.227638, change -0.019413, grad norm 18.175001, lr 0.004000
2021-05-21 20:34:15,748: <INFO> Epoch 90, loss 0.289044, change -0.061406, grad norm 31.465570, lr 0.004000
2021-05-21 20:34:18,699: <INFO> Epoch 95, loss 0.178736, change 0.110308, grad norm 9.238585, lr 0.004000
2021-05-21 20:34:21,683: <INFO> Epoch 100, loss 0.199427, change -0.020691, grad norm 18.420555, lr 0.004000
2021-05-21 20:34:24,647: <INFO> Epoch 105, loss 0.444206, change -0.244779, grad norm 69.367058, lr 0.004000
2021-05-21 20:34:27,594: <INFO> Epoch 110, loss 0.179879, change 0.264327, grad norm 17.761314, lr 0.004000
2021-05-21 20:34:30,528: <INFO> Epoch 115, loss 0.237263, change -0.057384, grad norm 33.867741, lr 0.004000
2021-05-21 20:34:33,399: <INFO> Epoch 120, loss 0.158056, change 0.079207, grad norm 20.813360, lr 0.004000
2021-05-21 20:34:36,399: <INFO> Epoch 125, loss 0.121214, change 0.036842, grad norm 4.484964, lr 0.004000
2021-05-21 20:34:39,397: <INFO> Epoch 130, loss 0.168788, change -0.047574, grad norm 12.783649, lr 0.004000
2021-05-21 20:34:42,418: <INFO> Epoch 135, loss 0.117056, change 0.051732, grad norm 6.775833, lr 0.004000
2021-05-21 20:34:45,659: <INFO> Epoch 140, loss 0.122640, change -0.005583, grad norm 6.463715, lr 0.004000
2021-05-21 20:34:48,447: <INFO> Epoch 145, loss 0.157116, change -0.034476, grad norm 20.239309, lr 0.004000
2021-05-21 20:34:51,463: <INFO> Epoch 150, loss 0.115835, change 0.041280, grad norm 7.312804, lr 0.004000
2021-05-21 20:34:54,219: <INFO> Epoch 155, loss 0.115212, change 0.000623, grad norm 11.504860, lr 0.004000
2021-05-21 20:34:56,956: <INFO> Epoch 160, loss 0.224218, change -0.109005, grad norm 37.789799, lr 0.004000
2021-05-21 20:34:59,722: <INFO> Epoch 165, loss 0.095360, change 0.128858, grad norm 4.858724, lr 0.004000
2021-05-21 20:35:02,441: <INFO> Epoch 170, loss 0.108381, change -0.013022, grad norm 9.228712, lr 0.004000
2021-05-21 20:35:05,296: <INFO> Epoch 175, loss 0.127733, change -0.019351, grad norm 12.404250, lr 0.004000
2021-05-21 20:35:08,356: <INFO> Epoch 180, loss 0.091667, change 0.036066, grad norm 3.862363, lr 0.004000
2021-05-21 20:35:11,546: <INFO> Epoch 185, loss 0.097365, change -0.005698, grad norm 3.318398, lr 0.004000
2021-05-21 20:35:14,568: <INFO> Epoch 190, loss 0.078201, change 0.019165, grad norm 2.925666, lr 0.004000
2021-05-21 20:35:17,609: <INFO> Epoch 195, loss 0.092343, change -0.014143, grad norm 8.267300, lr 0.004000
2021-05-21 20:35:20,598: <INFO> Epoch 200, loss 0.074742, change 0.017602, grad norm 4.703595, lr 0.004000
2021-05-21 20:35:23,577: <INFO> Epoch 205, loss 0.072191, change 0.002550, grad norm 2.995246, lr 0.004000
2021-05-21 20:35:26,350: <INFO> Epoch 210, loss 0.095098, change -0.022907, grad norm 8.649387, lr 0.004000
2021-05-21 20:35:29,492: <INFO> Epoch 215, loss 0.120361, change -0.025263, grad norm 19.798149, lr 0.004000
2021-05-21 20:35:32,095: <INFO> Epoch 220, loss 0.061801, change 0.058560, grad norm 1.905921, lr 0.004000
2021-05-21 20:35:34,596: <INFO> Epoch 225, loss 0.067744, change -0.005944, grad norm 2.461025, lr 0.004000
2021-05-21 20:35:37,093: <INFO> Epoch 230, loss 0.060618, change 0.007126, grad norm 1.403277, lr 0.004000
2021-05-21 20:35:39,598: <INFO> Epoch 235, loss 0.107352, change -0.046734, grad norm 16.569635, lr 0.004000
2021-05-21 20:35:42,141: <INFO> Epoch 240, loss 0.064503, change 0.042849, grad norm 4.126694, lr 0.004000
2021-05-21 20:35:45,086: <INFO> Epoch 245, loss 0.062113, change 0.002390, grad norm 4.649285, lr 0.004000
2021-05-21 20:35:48,372: <INFO> Epoch 250, loss 0.059767, change 0.002346, grad norm 3.691389, lr 0.004000
2021-05-21 20:35:51,669: <INFO> Epoch 255, loss 0.124506, change -0.064739, grad norm 23.697168, lr 0.004000
2021-05-21 20:35:54,157: <INFO> Epoch 260, loss 0.058332, change 0.066174, grad norm 2.017727, lr 0.004000
2021-05-21 20:35:56,657: <INFO> Epoch 265, loss 0.095620, change -0.037288, grad norm 14.673720, lr 0.004000
2021-05-21 20:35:59,242: <INFO> Epoch 270, loss 0.066119, change 0.029501, grad norm 3.654847, lr 0.004000
2021-05-21 20:36:01,788: <INFO> Epoch 275, loss 0.051323, change 0.014796, grad norm 2.082829, lr 0.004000
2021-05-21 20:36:04,320: <INFO> Epoch 280, loss 0.066679, change -0.015357, grad norm 5.347533, lr 0.004000
2021-05-21 20:36:06,825: <INFO> Epoch 285, loss 0.066801, change -0.000122, grad norm 7.681639, lr 0.004000
2021-05-21 20:36:09,350: <INFO> Epoch 290, loss 0.099004, change -0.032202, grad norm 14.896507, lr 0.004000
2021-05-21 20:36:11,902: <INFO> Epoch 295, loss 0.042599, change 0.056405, grad norm 0.736201, lr 0.004000
2021-05-21 20:36:14,412: <INFO> Epoch 300, loss 0.055491, change -0.012892, grad norm 3.676176, lr 0.004000
2021-05-21 20:36:16,918: <INFO> Epoch 305, loss 0.066859, change -0.011368, grad norm 9.754549, lr 0.004000
2021-05-21 20:36:19,424: <INFO> Epoch 310, loss 0.058123, change 0.008736, grad norm 5.521711, lr 0.004000
2021-05-21 20:36:21,939: <INFO> Epoch 315, loss 0.044203, change 0.013920, grad norm 2.238427, lr 0.004000
2021-05-21 20:36:24,436: <INFO> Epoch 320, loss 0.083775, change -0.039572, grad norm 10.701116, lr 0.004000
2021-05-21 20:36:26,977: <INFO> Epoch 325, loss 0.044563, change 0.039212, grad norm 1.685877, lr 0.004000
2021-05-21 20:36:29,672: <INFO> Epoch 330, loss 0.053229, change -0.008666, grad norm 5.616881, lr 0.004000
2021-05-21 20:36:32,864: <INFO> Epoch 335, loss 0.041609, change 0.011621, grad norm 1.229427, lr 0.004000
2021-05-21 20:36:35,510: <INFO> Epoch 340, loss 0.049461, change -0.007852, grad norm 5.433271, lr 0.004000
2021-05-21 20:36:38,136: <INFO> Epoch 345, loss 0.054015, change -0.004554, grad norm 8.100521, lr 0.004000
2021-05-21 20:36:40,749: <INFO> Epoch 350, loss 0.139305, change -0.085291, grad norm 22.025578, lr 0.004000
2021-05-21 20:36:43,220: <INFO> Epoch 355, loss 0.036542, change 0.102764, grad norm 1.214288, lr 0.004000
2021-05-21 20:36:45,694: <INFO> Epoch 360, loss 0.045486, change -0.008944, grad norm 1.160861, lr 0.004000
2021-05-21 20:36:48,289: <INFO> Epoch 365, loss 0.061115, change -0.015629, grad norm 8.503603, lr 0.004000
2021-05-21 20:36:50,783: <INFO> Epoch 370, loss 0.037083, change 0.024032, grad norm 1.871446, lr 0.004000
2021-05-21 20:36:53,351: <INFO> Epoch 375, loss 0.441376, change -0.404293, grad norm 48.022552, lr 0.004000
2021-05-21 20:36:56,054: <INFO> Epoch 380, loss 0.035380, change 0.405996, grad norm 2.612165, lr 0.004000
2021-05-21 20:37:00,103: <INFO> Epoch 385, loss 0.051702, change -0.016322, grad norm 4.922912, lr 0.004000
2021-05-21 20:37:02,742: <INFO> Epoch 390, loss 0.055650, change -0.003948, grad norm 6.028166, lr 0.004000
2021-05-21 20:37:05,309: <INFO> Epoch 395, loss 0.030133, change 0.025518, grad norm 0.786187, lr 0.004000
2021-05-21 20:37:08,023: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-05-21 20:37:08,049: <WARNING> From C:\Users\Teucros\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\training\tracking\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-05-21 20:37:10,203: <INFO> Assets written to: simple\assets
2021-05-21 20:37:10,254: <INFO> Best loss is 0.042766
